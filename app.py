import os
import json
import re
import unicodedata
import requests
from flask import Flask, request, jsonify
from dotenv import load_dotenv

# ============== OpenAI (ƒë·ªÉ hi·ªÉu intent & ‚Äúm∆∞·ª£t h√≥a‚Äù c√¢u tr·∫£ l·ªùi) ==============
try:
    from openai import OpenAI
except ImportError:
    OpenAI = None

# ============== ENV ==============
load_dotenv()

TELEGRAM_TOKEN = os.getenv("TELEGRAM_TOKEN", "")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY", "")

# Hotline, link ƒëi·ªÅu h∆∞·ªõng, tuy·∫øn tr√™n
HOTLINE_TUYEN_TREN = os.getenv("HOTLINE_TUYEN_TREN", "09xx.xxx.xxx")
LINK_KENH_TELEGRAM = os.getenv("LINK_KENH_TELEGRAM", "https://t.me/your_channel")
LINK_FANPAGE = os.getenv("LINK_FANPAGE", "https://facebook.com/your_fanpage")
LINK_WEBSITE = os.getenv("LINK_WEBSITE", "https://your-website.com")

# ID Telegram c·ªßa tuy·∫øn tr√™n (upline), d·∫°ng s·ªë (string trong .env)
UPLINE_CHAT_ID = os.getenv("UPLINE_CHAT_ID", "")

# L∆∞u c√¢u h·ªèi g·∫ßn nh·∫•t c·ªßa t·ª´ng chat
LAST_USER_TEXT = {}

# Tr·∫°ng th√°i quy tr√¨nh chuy·ªÉn tuy·∫øn tr√™n cho t·ª´ng chat
PENDING_UPLINE_STATE = {}  # "", "waiting_content", "waiting_confirm"
PENDING_UPLINE_TEXT = {}   # {"main_question": "..."}

# Webhook Apps Script ƒë·ªÉ log v√†o Google Sheets
LOG_SHEET_WEBHOOK_URL = os.getenv("LOG_SHEET_WEBHOOK_URL", "")

# ============== KI·ªÇM TRA ENV ==============
if not TELEGRAM_TOKEN:
    raise ValueError("Thi·∫øu TELEGRAM_TOKEN trong .env")

# ============== OpenAI CLIENT ==============
client = None
if OpenAI and OPENAI_API_KEY:
    client = OpenAI(api_key=OPENAI_API_KEY)

# ============== FLASK APP ==============
app = Flask(__name__)

# ============== ƒê∆Ø·ªúNG D·∫™N JSON ==============
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
PRODUCTS_PATH = os.path.join(BASE_DIR, "products.json")
COMBOS_PATH = os.path.join(BASE_DIR, "combos.json")
FAQ_BUY_PATH = os.path.join(BASE_DIR, "faq_buy.json")
FAQ_PAYMENT_PATH = os.path.join(BASE_DIR, "faq_payment.json")
FAQ_BUSINESS_PATH = os.path.join(BASE_DIR, "faq_business.json")

# 2 file m·ªõi:
HEALTH_TAGS_MAP_PATH = os.path.join(BASE_DIR, "health_tags_map.json")
SYNONYMS_PATH = os.path.join(BASE_DIR, "synonyms.json")

# ============== T·∫¢I D·ªÆ LI·ªÜU JSON ==============
def safe_load_json(path, default=None):
    if default is None:
        default = {}
    try:
        if not os.path.exists(path):
            return default
        with open(path, "r", encoding="utf-8") as f:
            data = json.load(f)
        return data
    except Exception as e:
        print(f"[WARN] Kh√¥ng ƒë·ªçc ƒë∆∞·ª£c JSON {path}: {e}")
        return default


def extract_list(data, key=None):
    """
    combos.json: { "combos": [ ... ] }
    products.json: { "products": [ ... ] }
    """
    if isinstance(data, list):
        return data
    if isinstance(data, dict) and key and isinstance(data.get(key), list):
        return data[key]
    return []


# ƒë·ªçc d·ªØ li·ªáu th·∫≠t s·ª± d√πng
combos_raw = safe_load_json(COMBOS_PATH, default={"combos": []})
products_raw = safe_load_json(PRODUCTS_PATH, default={"products": []})
faq_buy_data = safe_load_json(FAQ_BUY_PATH, default=[])
faq_payment_data = safe_load_json(FAQ_PAYMENT_PATH, default=[])
faq_business_data = safe_load_json(FAQ_BUSINESS_PATH, default=[])

combos_list = extract_list(combos_raw, "combos")
products_list = extract_list(products_raw, "products")

# 2 file m·ªõi
health_tags_map_data = safe_load_json(HEALTH_TAGS_MAP_PATH, default={})
synonyms_data = safe_load_json(SYNONYMS_PATH, default={})

# ============== H√ÄM TI·ªÜN √çCH CHUNG ==============
def normalize_text(text: str) -> str:
    if not text:
        return ""
    text = text.lower().strip()
    text = unicodedata.normalize("NFD", text)
    text = "".join(ch for ch in text if unicodedata.category(ch) != "Mn")
    return text


def strip_markdown(text: str) -> str:
    """
    Lo·∫°i b·ªè c√°c k√Ω hi·ªáu markdown ƒë∆°n gi·∫£n nh∆∞ **bold**, *italic* trong chu·ªói.
    Kh√¥ng ƒë·ªông v√†o th·∫ª HTML (<b>...</b>) m√† Telegram ƒëang d√πng.
    """
    if not isinstance(text, str):
        return text
    text = re.sub(r"\*\*(.*?)\*\*", r"\1", text)
    text = re.sub(r"\*(.*?)\*", r"\1", text)
    text = text.replace("*", "")
    return text.strip()


def text_contains(text: str, keyword: str) -> bool:
    return normalize_text(keyword) in normalize_text(text)


def send_telegram_message(chat_id, text, reply_to_message_id=None, parse_mode="HTML"):
    url = f"https://api.telegram.org/bot{TELEGRAM_TOKEN}/sendMessage"
    payload = {
        "chat_id": chat_id,
        "text": text,
        "parse_mode": parse_mode,
        "disable_web_page_preview": False,
    }
    if reply_to_message_id:
        payload["reply_to_message_id"] = reply_to_message_id

    try:
        resp = requests.post(url, json=payload, timeout=15)
        if resp.status_code != 200:
            print("[ERROR] Telegram sendMessage:", resp.text)
    except Exception as e:
        print("[ERROR] G·ª≠i tin nh·∫Øn Telegram l·ªói:", e)

# ============== LOG V√ÄO GOOGLE SHEET ==============
def log_event(
    log_type,
    chat_id,
    username="",
    role="",
    user_text="",
    bot_reply="",
    intent="",
    health_issue="",
    product_query="",
    ask_upline="",
    extra="",
    raw_payload=None,
):
    """
    G·ª≠i 1 d√≤ng log sang Apps Script (sheet "Welllab Bot Logs").
    Apps Script s·∫Ω t·ª± t·∫°o header, n√™n m√¨nh ch·ªâ c·∫ßn g·ª≠i key-value.
    """
    if not LOG_SHEET_WEBHOOK_URL:
        return
    try:
        payload = {
            "log_type": log_type,
            "source": "telegram",
            "chat_id": str(chat_id),
            "username": username or "",
            "role": role or "",
            "user_text": user_text or "",
            "bot_reply": bot_reply or "",
            "intent": intent or "",
            "health_issue": health_issue or "",
            "product_query": product_query or "",
            "ask_upline": ask_upline or "",
            "extra": extra or "",
        }
        if raw_payload is not None:
            payload["raw_payload"] = raw_payload
        requests.post(LOG_SHEET_WEBHOOK_URL, json=payload, timeout=10)
    except Exception as e:
        print("[WARN] log_event l·ªói:", e)


def fetch_last_upline_question(chat_id: str):
    """
    H·ªèi Apps Script xem c√¢u h·ªèi tuy·∫øn tr√™n g·∫ßn nh·∫•t c·ªßa chat_id l√† g√¨.
    (Apps Script x·ª≠ l√Ω action=getLastUplineQuestion)
    """
    if not LOG_SHEET_WEBHOOK_URL:
        return None
    try:
        url = f"{LOG_SHEET_WEBHOOK_URL}?action=getLastUplineQuestion&chat_id={chat_id}"
        resp = requests.get(url, timeout=10)
        if resp.status_code != 200:
            print("[WARN] fetch_last_upline_question HTTP:", resp.text)
            return None
        data = resp.json()
        if not data.get("ok"):
            return None
        q = (data.get("question") or "").strip()
        return q or None
    except Exception as e:
        print("[WARN] fetch_last_upline_question l·ªói:", e)
        return None


def fetch_history(chat_id: str, limit: int = 20):
    """
    (Chu·∫©n b·ªã cho t∆∞∆°ng lai) L·∫•y l·ªãch s·ª≠ h·ªôi tho·∫°i g·∫ßn nh·∫•t t·ª´ Apps Script.
    """
    if not LOG_SHEET_WEBHOOK_URL:
        return []
    try:
        url = f"{LOG_SHEET_WEBHOOK_URL}?action=getHistory&chat_id={chat_id}&limit={limit}"
        resp = requests.get(url, timeout=10)
        if resp.status_code != 200:
            print("[WARN] fetch_history HTTP:", resp.text)
            return []
        data = resp.json()
        if not data.get("ok"):
            return []
        return data.get("items") or []
    except Exception as e:
        print("[WARN] fetch_history l·ªói:", e)
        return []

# ============== ƒê·ªíNG B·ªò SYNONYMS & HEALTH TAGS ==============
def apply_synonyms(text: str) -> str:
    """
    Thay th·∫ø c√°c c·ª•m t·ª´ theo synonyms.json (bao t·ª≠ -> d·∫° d√†y, v.v.)
    Kh√¥ng ph√° v·ª° n·ªôi dung, ch·ªâ chu·∫©n h√≥a c√°ch g·ªçi.
    """
    if not text or not isinstance(synonyms_data, dict):
        return text
    result = text
    for k, v in synonyms_data.items():
        if not k or not v:
            continue
        try:
            pattern = re.compile(re.escape(k), flags=re.IGNORECASE)
            result = pattern.sub(v, result)
        except re.error:
            continue
    return result


def expand_health_issue(health_issue: str):
    """
    T·ª´ 1 c√¢u/ c·ª•m 'v·∫•n ƒë·ªÅ s·ª©c kho·∫ª' ‚Üí tr·∫£ v·ªÅ list:
    - [c√¢u g·ªëc, c√¢u sau khi √°p synonyms, c√°c health_tags trong health_tags_map n·∫øu match]
    """
    res = []
    if not health_issue:
        return res

    base = health_issue.strip()
    if base:
        res.append(base)

    syn = apply_synonyms(base)
    if syn and syn not in res:
        res.append(syn)

    try:
        h_norm = normalize_text(base)
        if isinstance(health_tags_map_data, dict):
            for key, tags in health_tags_map_data.items():
                try:
                    key_norm = normalize_text(str(key))
                except Exception:
                    continue
                if not key_norm:
                    continue
                if key_norm in h_norm or h_norm in key_norm:
                    if isinstance(tags, list):
                        for t in tags:
                            if t and t not in res:
                                res.append(t)
                    else:
                        if tags and tags not in res:
                            res.append(tags)
    except Exception as e:
        print("[WARN] expand_health_issue:", e)

    return res

# ============== T√åM KI·∫æM S·∫¢N PH·∫®M & COMBO ==============
def search_combo_by_health_issue(health_issue: str):
    if not health_issue:
        return None

    issues = expand_health_issue(health_issue)
    if not issues:
        issues = [health_issue]

    best_score = 0
    best_combo = None

    for combo in combos_list:
        name = combo.get("name", "")
        aliases = combo.get("aliases", [])
        health_tags = combo.get("health_tags", [])
        fields = [name] + aliases + health_tags

        score = 0
        for issue in issues:
            i_norm = normalize_text(issue)
            for field in fields:
                if text_contains(field, i_norm) or text_contains(i_norm, field):
                    score += 1

        if score > best_score:
            best_score = score
            best_combo = combo

    return best_combo


def search_product_by_health_issue(health_issue: str):
    if not health_issue:
        return []

    issues = expand_health_issue(health_issue)
    if not issues:
        issues = [health_issue]

    results = []
    for p in products_list:
        fields = []
        fields.append(p.get("name", ""))
        fields.extend(p.get("aliases", []))
        fields.extend(p.get("health_tags", []))
        main_tag = p.get("main_health_tag")
        if main_tag:
            fields.append(main_tag)

        match = False
        for issue in issues:
            i_norm = normalize_text(issue)
            for field in fields:
                if text_contains(field, i_norm) or text_contains(i_norm, field):
                    match = True
                    break
            if match:
                break

        if match:
            results.append(p)

    return results[:3]


def search_product_by_name_or_code(query: str):
    if not query:
        return None
    query = apply_synonyms(query)
    q_norm = normalize_text(query)
    best_score = 0
    best_product = None

    for p in products_list:
        code = p.get("code", "")
        name = p.get("name", "")
        aliases = p.get("aliases", [])
        fields = [code, name] + aliases
        score = 0
        for field in fields:
            if not field:
                continue
            if text_contains(field, q_norm) or text_contains(q_norm, field):
                score += 1
        if score > best_score:
            best_score = score
            best_product = p

    return best_product

# ============== OPENAI ‚Äì PH√ÇN T√çCH INTENT & NHU C·∫¶U ==============
def classify_intent_with_openai(user_text: str) -> dict:
    base_result = {
        "intent": "SMALL_TALK",
        "health_issue": None,
        "product_query": None,
        "needs": [],
        "ask_upline": False,
        "raw_reasoning": "",
    }

    if not client:
        # N·∫øu kh√¥ng c√≥ OpenAI th√¨ fallback keyword ƒë∆°n gi·∫£n
        t_raw = apply_synonyms(user_text or "")
        t = normalize_text(t_raw)

        # H·ªèi l·ªãch s·ª≠ / c√¢u v·ª´a h·ªèi
        if any(
            kw in t
            for kw in [
                "vua hoi gi",
                "vua hoi em gi",
                "vua hoi em cau gi",
                "vua hoi em cau hoi gi",
                "xem lai lich su",
                "xem lai cuoc tro chuyen",
                "lich su cuoc tro chuyen",
            ]
        ):
            base_result["intent"] = "META_HISTORY"
            return base_result

        # G·∫∑p tuy·∫øn tr√™n
        if any(
            k in t
            for k in [
                "ket noi tuyen tren",
                "ket noi voi tuyen tren",
                "gap tuyen tren",
                "muon gap tuyen tren",
                "muon noi voi tuyen tren",
                "chuyen cho tuyen tren",
                "can tuyen tren ho tro",
            ]
        ):
            base_result["intent"] = "BUSINESS_QUESTION"
            base_result["ask_upline"] = True
            return base_result

        if any(k in t for k in ["tieu duong", "dai thao duong"]):
            base_result["intent"] = "HEALTH_COMBO"
            base_result["health_issue"] = "ti·ªÉu ƒë∆∞·ªùng"
        elif any(k in t for k in ["da day", "bao tu", "trao nguoc"]):
            base_result["intent"] = "HEALTH_PRODUCT"
            base_result["health_issue"] = "ƒëau d·∫° d√†y / d·∫° d√†y"
        elif any(k in t for k in ["mua hang", "dat hang", "mua nhu the nao"]):
            base_result["intent"] = "HOW_TO_BUY"
        elif any(k in t for k in ["thanh toan", "chuyen khoan"]):
            base_result["intent"] = "HOW_TO_PAY"
        elif any(k in t for k in ["fanpage", "kenh", "website", "trang web"]):
            base_result["intent"] = "NAVIGATION"
        elif any(k in t for k in ["chinh sach", "hoa hong", "kinh doanh", "thuong", "chiet khau"]):
            base_result["intent"] = "BUSINESS_QUESTION"
        return base_result

    system_prompt = """
B·∫°n l√† tr·ª£ l√Ω AI n·ªôi b·ªô h·ªó tr·ª£ ƒë·ªôi ng≈© t∆∞ v·∫•n vi√™n (TVV) c·ªßa c√¥ng ty th·ª±c ph·∫©m chƒÉm s√≥c s·ª©c kh·ªèe.
Nhi·ªám v·ª•: ph√¢n t√≠ch c√¢u h·ªèi v√† tr·∫£ v·ªÅ JSON theo c·∫•u tr√∫c.

C√°c INTENT ch√≠nh:
- HEALTH_COMBO: TVV h·ªèi combo cho m·ªôt v·∫•n ƒë·ªÅ s·ª©c kh·ªèe (v√≠ d·ª•: ti·ªÉu ƒë∆∞·ªùng, huy·∫øt √°p, m·ª° m√°u...)
- HEALTH_PRODUCT: TVV h·ªèi s·∫£n ph·∫©m l·∫ª cho m·ªôt v·∫•n ƒë·ªÅ s·ª©c kh·ªèe.
- PRODUCT_DETAIL: TVV h·ªèi th√¥ng tin chi ti·∫øt v·ªÅ m·ªôt s·∫£n ph·∫©m c·ª• th·ªÉ (theo m√£ ho·∫∑c t√™n).
- HOW_TO_BUY: H·ªèi c√°ch mua h√†ng, ƒë·∫∑t h√†ng, quy tr√¨nh.
- HOW_TO_PAY: H·ªèi v·ªÅ c√°ch thanh to√°n, chuy·ªÉn kho·∫£n, COD.
- BUSINESS_QUESTION: H·ªèi v·ªÅ ch√≠nh s√°ch kinh doanh, hoa h·ªìng, chi·∫øt kh·∫•u, th∆∞·ªüng, quy ƒë·ªãnh n·ªôi b·ªô.
- NAVIGATION: H·ªèi xin link fanpage, k√™nh telegram, website, group ch√≠nh th·ª©c.
- SMALL_TALK: Ch√†o h·ªèi, c·∫£m ∆°n, c√¢u chuy·ªán chung chung.
- META_HISTORY: TVV h·ªèi v·ªÅ ch√≠nh cu·ªôc tr√≤ chuy·ªán, v√≠ d·ª•:
  "anh v·ª´a h·ªèi g√¨ nh·ªâ?", "xem l·∫°i l·ªãch s·ª≠ cu·ªôc tr√≤ chuy·ªán n√†y", "l·∫ßn tr∆∞·ªõc em n√≥i g√¨ v·ªõi anh?"

- N·∫øu TVV n√≥i c√°c c√¢u nh∆∞: "k·∫øt n·ªëi tuy·∫øn tr√™n", "anh mu·ªën g·∫∑p tuy·∫øn tr√™n", 
  "nh·ªù tuy·∫øn tr√™n tr·∫£ l·ªùi gi√∫p", "chuy·ªÉn c√¢u n√†y cho tuy·∫øn tr√™n", 
  th√¨:
  + intent = "BUSINESS_QUESTION"
  + ask_upline = true
  + health_issue c√≥ th·ªÉ ƒë·ªÉ null

Tr∆∞·ªùng "needs" l√† danh s√°ch c√°c nhu c·∫ßu c·ª• th·ªÉ trong c√πng 1 c√¢u:
- "combo": c·∫ßn t√™n combo
- "products": c·∫ßn danh s√°ch s·∫£n ph·∫©m trong combo
- "usage": c·∫ßn c√°ch d√πng/c√°ch u·ªëng
- "duration": c·∫ßn th·ªùi gian d√πng bao l√¢u ƒë·ªÉ c√≥ k·∫øt qu·∫£
- "product_links": c·∫ßn link s·∫£n ph·∫©m
- "benefits": c·∫ßn l·ª£i √≠ch/c√¥ng d·ª•ng
- "ingredients": c·∫ßn th√†nh ph·∫ßn s·∫£n ph·∫©m
- "how_to_buy": c·∫ßn h∆∞·ªõng d·∫´n mua h√†ng
- "how_to_pay": c·∫ßn h∆∞·ªõng d·∫´n thanh to√°n

Tr∆∞·ªùng "ask_upline":
- true: n·∫øu c√¢u h·ªèi thu·ªôc d·∫°ng BUSINESS_QUESTION kh√≥ ho·∫∑c nh·∫°y c·∫£m, n√™n chuy·ªÉn tuy·∫øn tr√™n.
- false: c√≤n l·∫°i.

Tr·∫£ v·ªÅ JSON v·ªõi c√°c field:
{
  "intent": "...",
  "health_issue": "... ho·∫∑c null",
  "product_query": "... ho·∫∑c null",
  "needs": [...],
  "ask_upline": false,
  "raw_reasoning": "gi·∫£i th√≠ch ng·∫Øn g·ªçn v√¨ sao ph√¢n lo·∫°i nh∆∞ v·∫≠y"
}

Lu√¥n tr·∫£ v·ªÅ ƒë√∫ng d·∫°ng JSON h·ª£p l·ªá.
"""

    # √Åp synonyms v√†o text tr∆∞·ªõc khi g·ª≠i l√™n OpenAI cho d·ªÖ hi·ªÉu
    processed_text = apply_synonyms(user_text or "")

    try:
        resp = client.chat.completions.create(
            model="gpt-4o-mini",
            response_format={"type": "json_object"},
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": processed_text},
            ],
        )
        content = resp.choices[0].message.content
        data = json.loads(content)
        
        for k, v in base_result.items():
            if k not in data:
                data[k] = v

        # Chu·∫©n h√≥a health_issue b·∫±ng synonyms lu√¥n
        if data.get("health_issue"):
            data["health_issue"] = apply_synonyms(data["health_issue"])

        return data
    except Exception as e:
        print("[ERROR] OpenAI classify_intent:", e)
        return base_result

# ============== BUILD C√ÇU TR·∫¢ L·ªúI ==============
def format_combo_reply(combo, needs, health_issue):
    if not combo:
        return (
            f"Hi·ªán t·∫°i em ch∆∞a t√¨m th·∫•y combo ph√π h·ª£p cho v·∫•n ƒë·ªÅ: <b>{health_issue}</b>.\n"
            "Anh/ch·ªã m√¥ t·∫£ r√µ h∆°n t√¨nh tr·∫°ng s·ª©c kho·∫ª ƒë·ªÉ em h·ªó tr·ª£ ch√≠nh x√°c h∆°n nh√©."
        )

    raw_name = combo.get("name", "Combo ph√π h·ª£p")
    raw_header_text = combo.get("header_text", "")
    duration_text = combo.get("duration_text", "")
    combo_url = combo.get("combo_url", "")
    products = combo.get("products", [])

    name = strip_markdown(raw_name)
    header_text = strip_markdown(raw_header_text)
    duration_text = strip_markdown(duration_text)

    lines = []
    lines.append(f"üéØ <b>{name}</b>")
    if header_text:
        lines.append(f"üìå {header_text}")

    if products:
        lines.append("\nüß© <b>C√°c s·∫£n ph·∫©m trong combo:</b>")
        for idx, p in enumerate(products, start=1):
            pname_combo = p.get("name") or p.get("product_name") or p.get("product_code") or "S·∫£n ph·∫©m"
            pname_combo = strip_markdown(pname_combo)

            # T√¨m s·∫£n ph·∫©m chi ti·∫øt
            product_detail = None
            for prod in products_list:
                if normalize_text(prod.get("name", "")) == normalize_text(pname_combo):
                    product_detail = prod
                    break
                if p.get("code") and normalize_text(prod.get("code", "")) == normalize_text(p.get("code", "")):
                    product_detail = prod
                    break

            price_text = strip_markdown(product_detail.get("price_text", "")) if product_detail else ""
            usage = strip_markdown(product_detail.get("usage_text", "")) if product_detail else ""
            product_url = (product_detail.get("product_url", "") or "").strip() if product_detail else ""
            role_text = strip_markdown(p.get("role_text", "")) if p.get("role_text") else ""
            dose_text = strip_markdown(p.get("dose_text", "")) if p.get("dose_text") else ""

            block_lines = []
            block_lines.append(f"\n<b>{idx}. {pname_combo}</b>")
            if role_text:
                block_lines.append(f"‚ñ™Ô∏è C√¥ng d·ª•ng ch√≠nh: {role_text}")
            if price_text:
                block_lines.append(f"üíµ Gi√° tham kh·∫£o: {price_text}")
            if dose_text:
                block_lines.append(f"üíä C√°ch d√πng (trong combo): {dose_text}")
            elif usage:
                block_lines.append(f"üíä C√°ch d√πng g·ª£i √Ω: {usage}")
            if product_url:
                block_lines.append(f"üîó Link s·∫£n ph·∫©m: {product_url}")
            else:
                block_lines.append(
                    "‚ö† S·∫£n ph·∫©m n√†y hi·ªán <b>kh√¥ng c√≥ link tr√™n h·ªá th·ªëng</b>, "
                    "c√≥ th·ªÉ ƒëang t·∫°m h·∫øt h√†ng ho·∫∑c ch∆∞a m·ªü b√°n online. "
                    "Anh/ch·ªã TVV ki·ªÉm tra l·∫°i kho/trang web tr∆∞·ªõc khi t∆∞ v·∫•n gi√∫p em nh√©."
                )

            lines.append("\n".join(block_lines))

    if duration_text:
        lines.append(f"\n‚è± <b>Th·ªùi gian khuy·∫øn ngh·ªã:</b> {duration_text}")
    if combo_url:
        lines.append(f"\nüõí <b>Link combo:</b> {combo_url}")

    lines.append(
        "\n‚ö†Ô∏è <i>L∆∞u √Ω: ƒê√¢y l√† s·∫£n ph·∫©m h·ªó tr·ª£, kh√¥ng thay th·∫ø thu·ªëc ƒëi·ªÅu tr·ªã. "
        "TVV n√™n h·ªèi k·ªπ t√¨nh tr·∫°ng b·ªánh v√† thu·ªëc kh√°ch ƒëang d√πng tr∆∞·ªõc khi t∆∞ v·∫•n, "
        "ƒë·∫∑c bi·ªát v·ªõi b·ªánh n·ªÅn n·∫∑ng ho·∫∑c ƒëang ƒëi·ªÅu tr·ªã chuy√™n khoa.</i>"
    )
    return "\n".join(lines)

def format_product_reply(product, needs, health_issue=None):
    if not product:
        if health_issue:
            return (
                f"Em ch∆∞a t√¨m th·∫•y s·∫£n ph·∫©m ph√π h·ª£p trong d·ªØ li·ªáu cho v·∫•n ƒë·ªÅ: <b>{health_issue}</b>.\n"
                "Anh/ch·ªã th·ª≠ m√¥ t·∫£ r√µ h∆°n tri·ªáu ch·ª©ng ho·∫∑c xin combo t·ªïng th·ªÉ ƒë·ªÉ t∆∞ v·∫•n d·ªÖ h∆°n nh√©."
            )
        return "Em ch∆∞a t√¨m th·∫•y s·∫£n ph·∫©m ph√π h·ª£p trong d·ªØ li·ªáu. Anh/ch·ªã ki·ªÉm tra l·∫°i t√™n ho·∫∑c m√£ s·∫£n ph·∫©m gi√∫p em nh√©."

    name = strip_markdown(product.get("name", "S·∫£n ph·∫©m"))
    code = strip_markdown(product.get("code", ""))
    ingredients = strip_markdown(product.get("ingredients_text", ""))
    benefits = strip_markdown(product.get("benefits_text", ""))
    usage = strip_markdown(product.get("usage_text", ""))
    price_text = strip_markdown(product.get("price_text", ""))
    duration_text = strip_markdown(product.get("duration_text", ""))
    product_url = (product.get("product_url", "") or "").strip()
    warnings = strip_markdown(product.get("notes_for_tvv", ""))

    lines = []
    title = f"<b>{name}</b>"
    if code:
        title += f" (M√£: {code})"
    lines.append(title)

    if price_text:
        lines.append(f"üí∞ Gi√° tham kh·∫£o: {price_text}")

    if (not needs) or ("ingredients" in needs):
        if ingredients:
            lines.append("")
            lines.append(f"<b>Th√†nh ph·∫ßn ch√≠nh:</b> {ingredients}")

    if (not needs) or ("benefits" in needs):
        if benefits:
            lines.append("")
            lines.append("<b>L·ª£i √≠ch n·ªïi b·∫≠t:</b>")
            lines.append(benefits)

    if (not needs) or ("usage" in needs):
        if usage:
            lines.append("")
            lines.append(f"<b>C√°ch d√πng khuy·∫øn ngh·ªã:</b> {usage}")

    if (not needs) or ("duration" in needs):
        if duration_text:
            lines.append("")
            lines.append(f"<b>Th·ªùi gian s·ª≠ d·ª•ng n√™n duy tr√¨:</b> {duration_text}")

    if (not needs) or ("product_links" in needs):
        if product_url:
            lines.append("")
            lines.append(f"üîó <b>Link s·∫£n ph·∫©m:</b> {product_url}")

    if warnings:
        lines.append("")
        lines.append(f"‚ö† <b>L∆∞u √Ω cho TVV:</b> {warnings}")

    lines.append("")
    lines.append(
        "Anh/ch·ªã TVV l∆∞u √Ω t∆∞ v·∫•n r√µ ƒë√¢y l√† s·∫£n ph·∫©m h·ªó tr·ª£, kh√¥ng thay th·∫ø thu·ªëc ƒëi·ªÅu tr·ªã, "
        "khuy·∫øn kh√≠ch kh√°ch tham kh·∫£o √Ω ki·∫øn b√°c sƒ© n·∫øu ƒëang d√πng thu·ªëc ho·∫∑c c√≥ b·ªánh n·ªÅn n·∫∑ng."
    )
    return "\n".join(lines)

def format_faq_reply(faq_list, key_field="title"):
    if not faq_list:
        return "Hi·ªán t·∫°i em ch∆∞a c√≥ d·ªØ li·ªáu h∆∞·ªõng d·∫´n chi ti·∫øt trong h·ªá th·ªëng. Anh/ch·ªã gi√∫p em li√™n h·ªá tuy·∫øn tr√™n ƒë·ªÉ ƒë∆∞·ª£c h·ªó tr·ª£ nh√©."

    if all(isinstance(x, str) for x in faq_list):
        return "\n".join(faq_list)

    lines = []
    for i, item in enumerate(faq_list, start=1):
        if isinstance(item, str):
            lines.append(item)
        elif isinstance(item, dict):
            title = strip_markdown(item.get(key_field, f"B∆∞·ªõc {i}"))
            content = strip_markdown(item.get("content", ""))
            line = f"{i}. <b>{title}</b>"
            if content:
                line += f"\n   {content}"
            lines.append(line)
    return "\n\n".join(lines)

def format_navigation_reply():
    lines = []
    lines.append("<b>C√°c k√™nh ch√≠nh th·ª©c c·ªßa c√¥ng ty:</b>")
    if LINK_KENH_TELEGRAM:
        lines.append(f"üì¢ K√™nh Telegram: {LINK_KENH_TELEGRAM}")
    if LINK_FANPAGE:
        lines.append(f"üëç Fanpage Facebook: {LINK_FANPAGE}")
    if LINK_WEBSITE:
        lines.append(f"üåê Website: {LINK_WEBSITE}")
    lines.append("")
    lines.append("Anh/ch·ªã TVV nh·ªõ ∆∞u ti√™n d·∫´n kh√°ch v√†o c√°c k√™nh ch√≠nh th·ª©c n√†y ƒë·ªÉ theo d√µi ch∆∞∆°ng tr√¨nh v√† th√¥ng tin m·ªõi nh·∫•t nh√©.")
    return "\n".join(lines)

# ============== X·ª¨ L√ù C√ÇU H·ªéI KINH DOANH & CHUY·ªÇN TUY·∫æN TR√äN ==============
def match_business_faq(user_text: str):
    """
    T√¨m c√¢u tr·∫£ l·ªùi trong faq_business_data n·∫øu c√≥.
    C·∫•u tr√∫c g·ª£i √Ω: [{"q_keywords":["hoa h·ªìng","chi·∫øt kh·∫•u"], "answer":"..."}]
    """
    if not faq_business_data:
        return None

    t_raw = apply_synonyms(user_text or "")
    t = normalize_text(t_raw)

    for item in faq_business_data:
        try:
            keywords = item.get("q_keywords", [])
            if not keywords:
                continue
            if all(normalize_text(k) in t for k in keywords):
                return item.get("answer")
        except Exception:
            continue
    return None

def escalate_to_upline(chat_id, username, main_question, extra_note=None):
    """
    G·ª≠i c√¢u h·ªèi l√™n tuy·∫øn tr√™n + log v√†o Sheet.
    """
    if not UPLINE_CHAT_ID:
        return (
            "Hi·ªán t·∫°i em ch∆∞a c·∫•u h√¨nh tuy·∫øn tr√™n trong h·ªá th·ªëng. "
            "Anh/ch·ªã vui l√≤ng li√™n h·ªá tr·ª±c ti·∫øp l√£nh ƒë·∫°o ƒë·ªÉ ƒë∆∞·ª£c h·ªó tr·ª£."
        )

    # Log ri√™ng c√¢u h·ªèi ch√≠nh g·ª≠i tuy·∫øn tr√™n
    log_event(
        log_type="UPLINE_QUESTION",
        chat_id=str(chat_id),
        username=username or "",
        role="user",
        user_text=main_question or "",
        ask_upline="yes",
        extra=extra_note or "",
    )

    msg_lines = [
        "üì® <b>Y√äU C·∫¶U H·ªñ TR·ª¢ TUY·∫æN TR√äN</b>",
        "",
        f"üë§ TVV: @{username if username else 'Kh√¥ng r√µ'}",
        f"üí¨ Chat ID: <code>{chat_id}</code>",
        "",
    ]

    if main_question:
        msg_lines.append("‚ùì <b>C√¢u h·ªèi ch√≠nh c·ªßa TVV:</b>")
        msg_lines.append(main_question)
        msg_lines.append("")
    if extra_note and extra_note.strip() != (main_question or "").strip():
        msg_lines.append("üìù <b>Ghi ch√∫ th√™m c·ªßa TVV:</b>")
        msg_lines.append(extra_note)
        msg_lines.append("")

    msg = "\n".join(msg_lines)
    send_telegram_message(UPLINE_CHAT_ID, msg, parse_mode="HTML")

    # Tin nh·∫Øn tr·∫£ l·∫°i cho TVV (echo l·∫°i n·ªôi dung ƒë√£ g·ª≠i)
    if main_question:
        return (
            "Em ƒë√£ g·ª≠i n·ªôi dung sau l√™n tuy·∫øn tr√™n gi√∫p anh/ch·ªã:\n"
            f"\"{main_question}\"\n\n"
            "Khi c√≥ ph·∫£n h·ªìi, em s·∫Ω g·ª≠i l·∫°i ngay ·∫°. üìû"
        )
    else:
        return (
            "Em ƒë√£ chuy·ªÉn y√™u c·∫ßu c·ªßa anh/ch·ªã l√™n tuy·∫øn tr√™n ƒë·ªÉ ƒë∆∞·ª£c h·ªó tr·ª£. "
            "Khi c√≥ ph·∫£n h·ªìi, em s·∫Ω b√°o l·∫°i ngay ·∫°. üìû"
        )

def handle_upline_reply(upline_text: str):
    """
    X·ª≠ l√Ω l·ªánh /reply t·ª´ tuy·∫øn tr√™n: /reply <chat_id> <n·ªôi dung>
    """
    parts = upline_text.split(maxsplit=2)
    if len(parts) < 3:
        return None, "Sai c√∫ ph√°p. D√πng: /reply <chat_id> <n·ªôi dung>"

    _, chat_id_str, content = parts
    if not chat_id_str.isdigit():
        return None, "Chat ID ph·∫£i l√† s·ªë. V√≠ d·ª•: /reply 123456789 N·ªôi dung tr·∫£ l·ªùi"

    return int(chat_id_str), content

# ============== X·ª¨ L√ù LOGIC CH√çNH ==============
def build_ai_style_reply(user_text: str, core_answer: str) -> str:
    """
    D√πng OpenAI ƒë·ªÉ l√†m m∆∞·ª£t c√¢u tr·∫£ l·ªùi, gi·ªØ nguy√™n n·ªôi dung core.
    """
    if not client:
        return core_answer

    prompt = f"""
B·∫°n l√† tr·ª£ l√Ω AI n·ªôi b·ªô, x∆∞ng h√¥ "em" v·ªõi TVV, TVV l√† "anh/ch·ªã".

Y√äU C·∫¶U B·∫ÆT BU·ªòC:
- Tr·∫£ l·ªùi b·∫±ng ti·∫øng Vi·ªát, th√¢n thi·ªán, r√µ r√†ng, d·ªÖ ƒë·ªçc.
- CH·ªà d√πng ƒë·ªãnh d·∫°ng HTML d√†nh cho Telegram: <b>...</b>, <i>...</i>.
- KH√îNG d√πng Markdown, KH√îNG d√πng **...**, *...* ho·∫∑c b·∫•t k·ª≥ k√Ω t·ª± * ƒë·ªÉ in ƒë·∫≠m.
- Kh√¥ng ƒë∆∞·ª£c xo√° hay b·ªãa th√™m th√¥ng tin v·ªÅ s·∫£n ph·∫©m, li·ªÅu d√πng, gi√°, th·ªùi gian s·ª≠ d·ª•ng.
- Gi·ªØ nguy√™n c√°c link (http/https) n·∫øu c√≥.

C√¢u h·ªèi c·ªßa TVV:
\"\"\"{user_text}\"\"\"

D∆∞·ªõi ƒë√¢y l√† n·ªôi dung c·ªët l√µi c·∫ßn truy·ªÅn ƒë·∫°t, b·∫°n ƒë∆∞·ª£c ph√©p ch·ªânh c√¢u ch·ªØ nh∆∞ng kh√¥ng ƒë∆∞·ª£c b·ªãa th√¥ng tin m·ªõi:
\"\"\"{core_answer}\"\"\"
"""
    try:
        resp = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {
                    "role": "system",
                    "content": (
                        "B·∫°n l√† tr·ª£ l√Ω b√°n h√†ng n·ªôi b·ªô cho ƒë·ªôi ng≈© TVV. "
                        "Lu√¥n tr·∫£ l·ªùi b·∫±ng ti·∫øng Vi·ªát, th√¢n thi·ªán, r√µ r√†ng. "
                        "Kh√¥ng d√πng Markdown, ch·ªâ d√πng HTML (<b>, <i>) n·∫øu c·∫ßn nh·∫•n m·∫°nh."
                    ),
                },
                {"role": "user", "content": prompt},
            ],
        )
        content = resp.choices[0].message.content or core_answer
        # Xo√° to√†n b·ªô d·∫•u **, * m√† OpenAI c√≥ th·ªÉ l·ª° ch√®n
        content = strip_markdown(content)
        return content
    except Exception as e:
        print("[ERROR] OpenAI build_ai_style_reply:", e)
        return core_answer

# ============== HELPER CHO FLOW TUY·∫æN TR√äN & L·ªäCH S·ª¨ ==============

def is_cancel_flow(text_norm: str) -> bool:
    """
    Nh·∫≠n di·ªán √Ω 'th√¥i / hu·ª∑ / kh√¥ng g·ª≠i n·ªØa' ƒë·ªÉ tho√°t flow tuy·∫øn tr√™n.
    """
    cancel_keywords = [
        "thoi", "th√¥i",
        "huy", "hu·ª∑", "h·ªßy",
        "khong gui nua", "kh√¥ng g·ª≠i n·ªØa",
        "khong can gui", "kh√¥ng c·∫ßn g·ª≠i",
        "khong can nua", "kh√¥ng c·∫ßn n·ªØa",
        "bo qua", "b·ªè qua",
        "cancel",
    ]
    return any(kw in text_norm for kw in cancel_keywords)


def is_confirm_send(text_norm: str) -> bool:
    """
    Nh·∫≠n di·ªán c√°c c√¢u x√°c nh·∫≠n: ƒë·ªìng √Ω g·ª≠i / ok g·ª≠i / g·ª≠i ƒëi...
    D√πng khi ƒëang ·ªü state 'waiting_confirm'.
    """
    # C√¢u tr·∫£ l·ªùi r·∫•t ng·∫Øn ki·ªÉu "ok", "ƒë·ªìng √Ω"
    short_confirms = [
        "ok",
        "ok em",
        "oke",
        "oke em",
        "dong y",
        "ƒë·ªìng √Ω",
        "chuan", "chu·∫©n",
        "duoc", "ƒë∆∞·ª£c",
    ]
    if text_norm in short_confirms:
        return True

    # C√¢u d√†i h∆°n nh∆∞ng c√≥ c·ª•m x√°c nh·∫≠n
    confirm_phrases = [
        "dong y gui", "ƒë·ªìng √Ω g·ª≠i",
        "ok gui", "ok g·ª≠i",
        "gui di", "g·ª≠i ƒëi",
        "gui len tuyen tren", "g·ª≠i l√™n tuy·∫øn tr√™n",
        "gui giup", "g·ª≠i gi√∫p",
    ]
    return any(kw in text_norm for kw in confirm_phrases)


def is_meta_history_query(text_norm: str) -> bool:
    """
    C√¢u ki·ªÉu: 'anh v·ª´a h·ªèi g√¨', 'anh v·ª´a y√™u c·∫ßu em g√¨',
    'xem l·∫°i l·ªãch s·ª≠', 'em v·ª´a n√≥i g√¨'...
    D√πng ƒë·ªÉ tr·∫£ l·ªùi l·ªãch s·ª≠, KH√îNG d√πng l√†m n·ªôi dung g·ª≠i tuy·∫øn tr√™n.
    """
    history_patterns = [
        "anh vua hoi gi", "anh v·ª´a h·ªèi g√¨",
        "anh vua yeu cau gi", "anh v·ª´a y√™u c·∫ßu g√¨",
        "anh vua yeu cau em gi", "anh v·ª´a y√™u c·∫ßu em g√¨",
        "xem lai lich su", "xem l·∫°i l·ªãch s·ª≠",
        "em vua noi gi", "em v·ª´a n√≥i g√¨",
        "em vua tra loi gi", "em v·ª´a tr·∫£ l·ªùi g√¨",
        "anh vua hoi em cau gi", "anh v·ª´a h·ªèi em c√¢u g√¨",
    ]
    return any(kw in text_norm for kw in history_patterns)


# ============== X·ª¨ L√ù TIN NH·∫ÆN CH√çNH ==============

def handle_user_message(chat_id, text, username=None, msg_id=None):
    global LAST_USER_TEXT, PENDING_UPLINE_STATE, PENDING_UPLINE_TEXT

    chat_key = str(chat_id)
    state = PENDING_UPLINE_STATE.get(chat_key, "")

    # Log tin nh·∫Øn ng∆∞·ªùi d√πng (lu√¥n log ngay ƒë·∫ßu)
    log_event(
        log_type="USER_MESSAGE",
        chat_id=chat_id,
        username=username or "",
        role="user",
        user_text=text,
    )

        # ===== C√ÇU H·ªéI L·ªäCH S·ª¨ / META_HISTORY =====
    t_norm = normalize_text(text)
    is_meta_history = False

    if ("lich su" in t_norm or "l·ªãch s·ª≠" in t_norm or "vua hoi" in t_norm or 
        "v·ª´a h·ªèi" in t_norm or "hoi gi nhi" in t_norm or "h·ªèi g√¨ nh·ªâ" in t_norm):

        is_meta_history = True

    if is_meta_history and state not in ["waiting_content", "waiting_confirm"]:
        # 1) L·∫•y l·ªãch s·ª≠ g·∫ßn nh·∫•t
        history = fetch_history(chat_key, limit=10) or []

        # 2) Lo·∫°i b·ªè ch√≠nh c√¢u v·ª´a h·ªèi
        filtered = []
        for item in history:
            q = (item.get("user_text") or "").strip()
            if normalize_text(q) == t_norm:
                continue  # b·ªè c√¢u hi·ªán t·∫°i
            filtered.append(item)

        # 3) R√∫t g·ªçn t·ªëi ƒëa 3‚Äì4 c·∫∑p
        filtered = filtered[:4]

        # 4) Format r√∫t g·ªçn ‚Äì kh√¥ng in full c√¢u d√†i
        lines = ["Em t√≥m t·∫Øt m·ªôt v√†i l∆∞·ª£t trao ƒë·ªïi g·∫ßn ƒë√¢y nh√©:\n"]

        if not filtered:
            lines.append("‚Ä¢ Hi·ªán t·∫°i em ch∆∞a t√¨m th·∫•y l·ªãch s·ª≠ tr∆∞·ªõc ƒë√≥ ·∫°.")
        else:
            for item in filtered:
                q = (item.get("user_text") or "").strip()
                a = (item.get("bot_reply") or "").strip()

                # R√∫t g·ªçn ph·∫ßn tr·∫£ l·ªùi qu√° d√†i
                if len(a) > 200:
                    a = a[:200].rstrip() + "‚Ä¶"

                if q:
                    lines.append(f"‚Ä¢ Anh/ch·ªã h·ªèi: {q}")
                if a:
                    lines.append(f"  ‚Üí Em tr·∫£ l·ªùi: {a}")
                lines.append("")

        reply_text_core = "\n".join(lines).strip()
        final_reply = build_ai_style_reply(text, reply_text_core)
        send_telegram_message(chat_id, final_reply, reply_to_message_id=msg_id)

        log_event(
            log_type="BOT_REPLY",
            chat_id=chat_id,
            username=username or "",
            role="bot",
            bot_reply=final_reply,
            intent="META_HISTORY",
        )
        LAST_USER_TEXT[chat_key] = text
        return

    # ===== 0.1. META_HISTORY CHUNG: 'anh v·ª´a h·ªèi g√¨ / v·ª´a y√™u c·∫ßu g√¨ / xem l·∫°i l·ªãch s·ª≠...' =====
    if is_meta_history_query(t_norm):
        last_user = LAST_USER_TEXT.get(chat_key, "")
        history_items = fetch_history(chat_key, limit=5)  # c√≥ th·ªÉ r·ªóng n·∫øu Apps Script ch∆∞a l√†m

        if history_items:
            # Tu·ª≥ c·∫•u tr√∫c Apps Script tr·∫£ v·ªÅ, gi·∫£ s·ª≠ m·ªói item c√≥: user_text, bot_reply
            lines = ["Em t√≥m t·∫Øt m·ªôt v√†i l∆∞·ª£t trao ƒë·ªïi g·∫ßn ƒë√¢y nh√©:"]
            for item in history_items:
                u = item.get("user_text", "").strip()
                b = item.get("bot_reply", "").strip()
                if not u and not b:
                    continue
                lines.append(f"‚Ä¢ Anh/ch·ªã h·ªèi: {u}")
                if b:
                    lines.append(f"  ‚Üí Em tr·∫£ l·ªùi: {b[:200]}{'...' if len(b) > 200 else ''}")
            reply_text_core = "\n".join(lines)
        elif last_user:
            reply_text_core = (
                "Ngay tr∆∞·ªõc c√¢u n√†y, anh/ch·ªã v·ª´a h·ªèi em:\n"
                f"\"{last_user}\"\n\n"
                "N·∫øu anh/ch·ªã mu·ªën em g·ª≠i c√¢u h·ªèi n√†o l√™n tuy·∫øn tr√™n th√¨ nh·∫Øn l·∫°i r√µ n·ªôi dung gi√∫p em nh√©."
            )
        else:
            reply_text_core = (
                "Hi·ªán t·∫°i em ch∆∞a l∆∞u ƒë∆∞·ª£c l·ªãch s·ª≠ c√¢u h·ªèi tr∆∞·ªõc ƒë√≥ c·ªßa anh/ch·ªã trong phi√™n n√†y. "
                "Anh/ch·ªã c√≥ th·ªÉ nh·∫Øn l·∫°i n·ªôi dung c·∫ßn h·ªèi, em s·∫Ω h·ªó tr·ª£ ngay ·∫°."
            )

        final_reply = build_ai_style_reply(text, reply_text_core)
        send_telegram_message(chat_id, final_reply, reply_to_message_id=msg_id)

        log_event(
            log_type="BOT_REPLY",
            chat_id=chat_id,
            username=username or "",
            role="bot",
            bot_reply=final_reply,
            intent="META_HISTORY",
        )

        LAST_USER_TEXT[chat_key] = text
        return

    # ===== 0.2. N·∫æU ƒêANG ·ªû FLOW TUY·∫æN TR√äN M√Ä NG∆Ø·ªúI D√ôNG N√ìI 'TH√îI / HU·ª∂' ‚Üí THO√ÅT FLOW =====
    if state in ("waiting_content", "waiting_confirm") and is_cancel_flow(t_norm):
        PENDING_UPLINE_STATE.pop(chat_key, None)
        PENDING_UPLINE_TEXT.pop(chat_key, None)

        reply_text_core = (
            "D·∫° em ƒë√£ <b>h·ªßy vi·ªác g·ª≠i c√¢u h·ªèi l√™n tuy·∫øn tr√™n</b> cho cu·ªôc tr√≤ chuy·ªán n√†y.\n"
            "Anh/ch·ªã c·ª© ti·∫øp t·ª•c h·ªèi c√°c n·ªôi dung kh√°c, em s·∫Ω h·ªó tr·ª£ nh∆∞ b√¨nh th∆∞·ªùng ·∫°."
        )

        final_reply = build_ai_style_reply(text, reply_text_core)
        send_telegram_message(chat_id, final_reply, reply_to_message_id=msg_id)

        log_event(
            log_type="BOT_REPLY",
            chat_id=chat_id,
            username=username or "",
            role="bot",
            bot_reply=final_reply,
            intent="CANCEL_UPLINE_FLOW",
        )

        LAST_USER_TEXT[chat_key] = text
        return

    reply_text_core = ""
    ask_upline_flag = False

    # ===== 1. ƒêANG ·ªû TR·∫†NG TH√ÅI CH·ªú TVV NH·∫¨P N·ªòI DUNG C√ÇU H·ªéI G·ª¨I TUY·∫æN TR√äN =====
    if state == "waiting_content":
        main_question = text.strip()
        if not main_question:
            reply_text_core = (
                "Em ch∆∞a th·∫•y anh/ch·ªã nh·∫≠p n·ªôi dung c√¢u h·ªèi. "
                "Anh/ch·ªã g√µ r√µ gi√∫p em n·ªôi dung mu·ªën g·ª≠i tuy·∫øn tr√™n nh√©."
            )
            final_reply = build_ai_style_reply(text, reply_text_core)
            send_telegram_message(chat_id, final_reply, reply_to_message_id=msg_id)

            log_event(
                log_type="BOT_REPLY",
                chat_id=chat_id,
                username=username or "",
                role="bot",
                bot_reply=final_reply,
                intent="BUSINESS_QUESTION",
                ask_upline="pending",
            )
            LAST_USER_TEXT[chat_key] = text
            return

        # L∆∞u c√¢u h·ªèi, chuy·ªÉn sang b∆∞·ªõc x√°c nh·∫≠n
        PENDING_UPLINE_TEXT[chat_key] = {"main_question": main_question}
        PENDING_UPLINE_STATE[chat_key] = "waiting_confirm"

        reply_text_core = (
            "Em ghi l·∫°i n·ªôi dung c√¢u h·ªèi ƒë·ªÉ g·ª≠i tuy·∫øn tr√™n nh∆∞ sau:\n"
            f"\"{main_question}\"\n\n"
            "Anh/ch·ªã xem gi√∫p em ƒë√£ ƒë√∫ng √Ω ch∆∞a ·∫°?\n"
            "‚Ä¢ N·∫øu ƒê√öNG, anh/ch·ªã tr·∫£ l·ªùi: <b>ƒê·ªìng √Ω</b>, <b>ƒê·ªìng √Ω g·ª≠i</b>, <b>OK</b> ho·∫∑c <b>G·ª≠i ƒëi</b>.\n"
            "‚Ä¢ N·∫øu C·∫¶N S·ª¨A, anh/ch·ªã nh·∫Øn l·∫°i n·ªôi dung m·ªõi, em s·∫Ω c·∫≠p nh·∫≠t tr∆∞·ªõc khi g·ª≠i."
        )

        final_reply = build_ai_style_reply(text, reply_text_core)
        send_telegram_message(chat_id, final_reply, reply_to_message_id=msg_id)

        log_event(
            log_type="BOT_REPLY",
            chat_id=chat_id,
            username=username or "",
            role="bot",
            bot_reply=final_reply,
            intent="BUSINESS_QUESTION",
            ask_upline="waiting_confirm",
        )
        LAST_USER_TEXT[chat_key] = text
        return

    # ===== 2. ƒêANG ·ªû TR·∫†NG TH√ÅI CH·ªú X√ÅC NH·∫¨N G·ª¨I TUY·∫æN TR√äN =====
    if state == "waiting_confirm":
        confirm_norm = t_norm
        main_question = (PENDING_UPLINE_TEXT.get(chat_key) or {}).get("main_question", "")

        if is_confirm_send(confirm_norm) and main_question:
            # G·ª≠i tuy·∫øn tr√™n th·∫≠t s·ª±
            reply_text_core = escalate_to_upline(
                chat_id=chat_id,
                username=username,
                main_question=main_question,
                extra_note=None,
            )

            # Xo√° tr·∫°ng th√°i ch·ªù
            PENDING_UPLINE_STATE.pop(chat_key, None)
            PENDING_UPLINE_TEXT.pop(chat_key, None)

            final_reply = build_ai_style_reply(text, reply_text_core)
            send_telegram_message(chat_id, final_reply, reply_to_message_id=msg_id)

            log_event(
                log_type="BOT_REPLY",
                chat_id=chat_id,
                username=username or "",
                role="bot",
                bot_reply=final_reply,
                intent="BUSINESS_QUESTION",
                ask_upline="yes",
            )
            LAST_USER_TEXT[chat_key] = text
            return
        else:
            # Xem tin nh·∫Øn n√†y nh∆∞ n·ªôi dung M·ªöI c·∫ßn g·ª≠i tuy·∫øn tr√™n
            main_question = text.strip()
            PENDING_UPLINE_TEXT[chat_key] = {"main_question": main_question}
            PENDING_UPLINE_STATE[chat_key] = "waiting_confirm"

            reply_text_core = (
                "Em hi·ªÉu l√† anh/ch·ªã mu·ªën ch·ªânh l·∫°i n·ªôi dung c√¢u h·ªèi. "
                "Hi·ªán t·∫°i em s·∫Ω chu·∫©n b·ªã g·ª≠i v·ªõi n·ªôi dung:\n"
                f"\"{main_question}\"\n\n"
                "Anh/ch·ªã ki·ªÉm tra gi√∫p em, n·∫øu ƒê√öNG th√¨ tr·∫£ l·ªùi: <b>ƒê·ªìng √Ω</b> ho·∫∑c <b>OK g·ª≠i</b>. "
                "N·∫øu v·∫´n ch∆∞a ƒë√∫ng, anh/ch·ªã g√µ l·∫°i n·ªôi dung m·ªõi nh√©."
            )

            final_reply = build_ai_style_reply(text, reply_text_core)
            send_telegram_message(chat_id, final_reply, reply_to_message_id=msg_id)

            log_event(
                log_type="BOT_REPLY",
                chat_id=chat_id,
                username=username or "",
                role="bot",
                bot_reply=final_reply,
                intent="BUSINESS_QUESTION",
                ask_upline="waiting_confirm",
            )
            LAST_USER_TEXT[chat_key] = text
            return

    # ===== 3. TR∆Ø·ªúNG H·ª¢P B√åNH TH∆Ø·ªúNG: PH√ÇN T√çCH INTENT & TR·∫¢ L·ªúI =====
    intent_info = classify_intent_with_openai(text)
    intent = intent_info.get("intent", "SMALL_TALK")
    health_issue = intent_info.get("health_issue")
    product_query = intent_info.get("product_query")
    needs = intent_info.get("needs") or []
    ask_upline_flag = bool(intent_info.get("ask_upline", False))

    if intent == "HEALTH_COMBO":
        combo = search_combo_by_health_issue(health_issue or text)
        reply_text_core = format_combo_reply(combo, needs, health_issue or text)

    elif intent == "HEALTH_PRODUCT":
        if product_query:
            product = search_product_by_name_or_code(product_query)
            reply_text_core = format_product_reply(product, needs, health_issue=None)
        else:
            products = search_product_by_health_issue(health_issue or text)
            if not products:
                reply_text_core = format_product_reply(None, needs, health_issue or text)
            elif len(products) == 1:
                reply_text_core = format_product_reply(products[0], needs, health_issue or text)
            else:
                lines = [f"<b>M·ªôt s·ªë s·∫£n ph·∫©m ph√π h·ª£p v·ªõi v·∫•n ƒë·ªÅ {health_issue or text}:</b>"]
                for p in products:
                    name = strip_markdown(p.get("name", "S·∫£n ph·∫©m"))
                    code = strip_markdown(p.get("code", ""))
                    url = (p.get("product_url", "") or "").strip()
                    line = f"‚Ä¢ {name}"
                    if code:
                        line += f" (M√£: {code})"
                    if url:
                        line += f"\n   üîó {url}"
                    lines.append(line)
                lines.append("")
                lines.append("N·∫øu anh/ch·ªã mu·ªën xem chi ti·∫øt s·∫£n ph·∫©m n√†o, h√£y h·ªèi theo t√™n ho·∫∑c m√£ s·∫£n ph·∫©m c·ª• th·ªÉ nh√©.")
                reply_text_core = "\n".join(lines)

    elif intent == "PRODUCT_DETAIL":
        product = search_product_by_name_or_code(product_query or text)
        reply_text_core = format_product_reply(product, needs, health_issue=None)

    elif intent == "HOW_TO_BUY":
        reply_text_core = format_faq_reply(faq_buy_data)

    elif intent == "HOW_TO_PAY":
        reply_text_core = format_faq_reply(faq_payment_data)

    elif intent == "NAVIGATION":
        reply_text_core = format_navigation_reply()

    elif intent == "BUSINESS_QUESTION":
        faq_answer = match_business_faq(text)
        if faq_answer:
            reply_text_core = faq_answer
        else:
            # Lu√¥n b·∫Øt ng∆∞·ªùi d√πng nh·∫≠p n·ªôi dung c·ª• th·ªÉ tr∆∞·ªõc khi g·ª≠i tuy·∫øn tr√™n
            ask_upline_flag = True
            PENDING_UPLINE_STATE[chat_key] = "waiting_content"
            PENDING_UPLINE_TEXT.pop(chat_key, None)
            reply_text_core = (
                "V·∫•n ƒë·ªÅ n√†y thu·ªôc nh√≥m ch√≠nh s√°ch/kinh doanh ho·∫∑c t√¨nh hu·ªëng kh√≥.\n\n"
                "Anh/ch·ªã cho em <b>n·ªôi dung c√¢u h·ªèi c·ª• th·ªÉ</b> mu·ªën g·ª≠i tuy·∫øn tr√™n "
                "(t√¨nh hu·ªëng, s·∫£n ph·∫©m/combo, m·ª©c gi√°, ch√≠nh s√°ch...), "
                "em s·∫Ω ghi l·∫°i r·ªìi nh·∫Øc l·∫°i ƒë·ªÉ anh/ch·ªã x√°c nh·∫≠n tr∆∞·ªõc khi g·ª≠i ƒëi ·∫°."
            )

    else:
        reply_text_core = (
            "Em l√† tr·ª£ l√Ω AI n·ªôi b·ªô h·ªó tr·ª£ anh/ch·ªã TVV trong vi·ªác t∆∞ v·∫•n s·∫£n ph·∫©m, combo v√† c√°ch chƒÉm s√≥c s·ª©c kho·∫ª.\n\n"
            "Anh/ch·ªã c√≥ th·ªÉ h·ªèi em v·ªÅ:\n"
            "‚Ä¢ Combo cho m·ªôt v·∫•n ƒë·ªÅ s·ª©c kh·ªèe (v√≠ d·ª•: ti·ªÉu ƒë∆∞·ªùng, d·∫° d√†y, x∆∞∆°ng kh·ªõp...)\n"
            "‚Ä¢ Th√¥ng tin chi ti·∫øt m·ªôt s·∫£n ph·∫©m (th√†nh ph·∫ßn, l·ª£i √≠ch, c√°ch d√πng...)\n"
            "‚Ä¢ C√°ch mua h√†ng, thanh to√°n, k√™nh ch√≠nh th·ª©c c·ªßa c√¥ng ty\n"
            "‚Ä¢ Nh·ªØng th·∫Øc m·∫Øc v·ªÅ kinh doanh, ch√≠nh s√°ch (em s·∫Ω h·ªó tr·ª£ chuy·ªÉn tuy·∫øn tr√™n n·∫øu c·∫ßn) üòä"
        )

    final_reply = build_ai_style_reply(text, reply_text_core)
    send_telegram_message(chat_id, final_reply, reply_to_message_id=msg_id)

    log_event(
        log_type="BOT_REPLY",
        chat_id=chat_id,
        username=username or "",
        role="bot",
        bot_reply=final_reply,
        intent=intent,
        health_issue=health_issue or "",
        product_query=product_query or "",
        ask_upline="yes" if ask_upline_flag else "no",
    )

    LAST_USER_TEXT[chat_key] = text

# ============== ROUTES FLASK ==============
@app.route("/", methods=["GET"])
def index():
    return jsonify({"status": "ok", "message": "Welllab AI Assistant is running."})

@app.route("/webhook", methods=["POST"])
def telegram_webhook():
    update = request.get_json(force=True, silent=True) or {}

    message = update.get("message") or update.get("edited_message")
    if not message:
        return jsonify({"ok": True})

    chat = message.get("chat", {})
    chat_id = chat.get("id")
    from_user = message.get("from", {})
    username = from_user.get("username") or from_user.get("first_name")
    text = message.get("text", "") or ""

    if not chat_id:
        return jsonify({"ok": True})

    # Tin nh·∫Øn t·ª´ tuy·∫øn tr√™n
    if UPLINE_CHAT_ID and str(chat_id) == str(UPLINE_CHAT_ID):
        if text.startswith("/reply"):
            target_chat_id, content = handle_upline_reply(text)
            if not target_chat_id:
                send_telegram_message(chat_id, content)
            else:
                # G·ª≠i n·ªôi dung cho TVV
                send_telegram_message(target_chat_id, f"üì£ Ph·∫£n h·ªìi t·ª´ tuy·∫øn tr√™n:\n\n{content}")
                send_telegram_message(chat_id, "ƒê√£ g·ª≠i tr·∫£ l·ªùi cho TVV.")

                # Log l·∫°i ph·∫£n h·ªìi tuy·∫øn tr√™n
                log_event(
                    log_type="UPLINE_REPLY",
                    chat_id=target_chat_id,
                    username=username or "",
                    role="upline",
                    bot_reply=content,
                )
        else:
            send_telegram_message(
                chat_id,
                "ƒê√¢y l√† k√™nh tuy·∫øn tr√™n. ƒê·ªÉ tr·∫£ l·ªùi TVV, d√πng l·ªánh:\n/reply <chat_id> <n·ªôi dung>",
            )
        return jsonify({"ok": True})

    # L·ªánh /start
    if text.startswith("/start"):
        welcome = (
            "Ch√†o anh/ch·ªã, em l√† <b>Tr·ª£ l√Ω AI Welllab</b> h·ªó tr·ª£ ƒë·ªôi ng≈© TVV üíö\n\n"
            "Anh/ch·ªã c√≥ th·ªÉ h·ªèi em v·ªÅ:\n"
            "‚Ä¢ Combo cho c√°c v·∫•n ƒë·ªÅ s·ª©c kh·ªèe (ti·ªÉu ƒë∆∞·ªùng, d·∫° d√†y, m·ª° m√°u, x∆∞∆°ng kh·ªõp...)\n"
            "‚Ä¢ Th√¥ng tin chi ti·∫øt s·∫£n ph·∫©m (th√†nh ph·∫ßn, l·ª£i √≠ch, c√°ch d√πng...)\n"
            "‚Ä¢ C√°ch mua h√†ng, thanh to√°n, k√™nh ch√≠nh th·ª©c c·ªßa c√¥ng ty\n"
            "‚Ä¢ C√¢u h·ªèi kinh doanh, ch√≠nh s√°ch (em s·∫Ω h·ªó tr·ª£ chuy·ªÉn tuy·∫øn tr√™n n·∫øu c·∫ßn)\n\n"
            "Anh/ch·ªã c·ª© nh·∫Øn t·ª± nhi√™n nh∆∞ ƒëang h·ªèi m·ªôt leader nh√© ü•∞"
        )
        send_telegram_message(chat_id, welcome, reply_to_message_id=message.get("message_id"))

        log_event(
            log_type="BOT_REPLY",
            chat_id=chat_id,
            username=username or "",
            role="bot",
            bot_reply=welcome,
            intent="START",
        )
        return jsonify({"ok": True})

    # C√°c tin nh·∫Øn c√≤n l·∫°i
    handle_user_message(chat_id, text, username=username, msg_id=message.get("message_id"))

    return jsonify({"ok": True})

# ============== MAIN ==============
if __name__ == "__main__":
    port = int(os.getenv("PORT", "8000"))
    app.run(host="0.0.0.0", port=port)


