import os
import json
import re
import requests
from flask import Flask, request, jsonify
from dotenv import load_dotenv

# ============== OpenAI (t√πy ch·ªçn, ƒë·ªÉ hi·ªÉu intent & m∆∞·ª£t c√¢u tr·∫£ l·ªùi) ==============
try:
    from openai import OpenAI
except ImportError:
    OpenAI = None

# ============== ENV ==============
load_dotenv()

TELEGRAM_TOKEN        = os.getenv("TELEGRAM_TOKEN", "")
HOTLINE_TUYEN_TREN    = os.getenv("HOTLINE_TUYEN_TREN", "09xx.xxx.xxx")
LINK_KENH_TELEGRAM    = os.getenv("LINK_KENH_TELEGRAM", "https://t.me/...")
LINK_FANPAGE          = os.getenv("LINK_FANPAGE", "https://facebook.com/...")
LINK_WEBSITE          = os.getenv("LINK_WEBSITE", "https://...")
OPENAI_API_KEY        = os.getenv("OPENAI_API_KEY", "")
LOG_SHEET_WEBHOOK_URL = os.getenv("LOG_SHEET_WEBHOOK_URL", "")

# Chat id nh√≥m / leader tuy·∫øn tr√™n ƒë·ªÉ forward y√™u c·∫ßu h·ªó tr·ª£
UPLINE_CHAT_ID        = os.getenv("UPLINE_CHAT_ID", "")  # v√≠ d·ª•: "-1001234567890"

ENABLE_AI_POLISH      = os.getenv("ENABLE_AI_POLISH", "true").lower() == "true"

if not TELEGRAM_TOKEN:
    raise RuntimeError("Ch∆∞a c·∫•u h√¨nh TELEGRAM_TOKEN trong .env")

TELEGRAM_API = f"https://api.telegram.org/bot{TELEGRAM_TOKEN}"

# ============== OpenAI client (n·∫øu c√≥) ==============
client = None
if OPENAI_API_KEY and OpenAI is not None:
    client = OpenAI(api_key=OPENAI_API_KEY)

# ============== Tr·∫°ng th√°i h·ªôi tho·∫°i ==============
# L∆∞u tr·∫°ng th√°i: TVV v·ª´a b·∫•m "K·∫øt n·ªëi tuy·∫øn tr√™n" v√† ƒëang chu·∫©n b·ªã g·ª≠i c√¢u h·ªèi
ESCALATION_PENDING: dict[int, bool] = {}  # {chat_id: True}

# L∆∞u context h·ªôi tho·∫°i ng·∫Øn h·∫°n cho t·ª´ng TVV
CHAT_CONTEXT: dict[int, dict] = {}  # {chat_id: {...}}

# ============== Load data (products.json + combos.json + meta) ==============
BASE_DIR = os.path.dirname(__file__)
DATA_DIR = os.path.join(BASE_DIR, "data")

def load_json(path, default):
    try:
        with open(path, "r", encoding="utf-8") as f:
            return json.load(f)
    except FileNotFoundError:
        return default

PRODUCTS_DATA = load_json(os.path.join(DATA_DIR, "products.json"), [])
COMBOS_DATA   = load_json(os.path.join(DATA_DIR, "combos.json"), [])

# Ch·∫•p nh·∫≠n format {"products":[...]} ho·∫∑c list th·∫≥ng
PRODUCTS = PRODUCTS_DATA.get("products", PRODUCTS_DATA)
COMBOS   = COMBOS_DATA.get("combos", COMBOS_DATA)

HEALTH_TAGS_INFO    = load_json(os.path.join(DATA_DIR, "health_tags_info.json"), {})
SYMPTOMS_MAP_RAW    = load_json(os.path.join(DATA_DIR, "symptoms_map.json"), {})
PRODUCT_ALIASES_RAW = load_json(os.path.join(DATA_DIR, "product_aliases.json"), {})

# alias_norm -> [codes]
PRODUCT_ALIASES_BY_ALIAS = PRODUCT_ALIASES_RAW.get("by_alias", PRODUCT_ALIASES_RAW)

# ============== Health tag labels ==============
HEALTH_TAG_LABELS = {
    "tieu_duong": "h·ªó tr·ª£ ·ªïn ƒë·ªãnh ƒë∆∞·ªùng huy·∫øt, ti·ªÉu ƒë∆∞·ªùng",
    "tieu_hoa": "h·ªó tr·ª£ ti√™u h√≥a, ƒë∆∞·ªùng ru·ªôt",
    "gan": "h·ªó tr·ª£ ch·ª©c nƒÉng gan, th·∫£i ƒë·ªôc gan",
    "thai_doc": "th·∫£i ƒë·ªôc, gi·∫£i ƒë·ªôc c∆° th·ªÉ",
    "mien_dich": "tƒÉng c∆∞·ªùng h·ªá mi·ªÖn d·ªãch",
    "tim_mach": "h·ªó tr·ª£ tim m·∫°ch, huy·∫øt √°p",
    "xuong_khop": "h·ªó tr·ª£ x∆∞∆°ng kh·ªõp, gi·∫£m ƒëau kh·ªõp",
    "than": "h·ªó tr·ª£ th·∫≠n ‚Äì ti·∫øt ni·ªáu",
    "ung_thu": "h·ªó tr·ª£ b·ªánh l√Ω/u b∆∞·ªõu, ung th∆∞ (k·∫øt h·ª£p ph√°c ƒë·ªì)",
    "giam_mo": "gi·∫£m m·ª°, ki·ªÉm so√°t c√¢n n·∫∑ng",
}

# B·ªï sung/ghi ƒë√® nh√£n t·ª´ file health_tags_info.json (n·∫øu c√≥)
for _tag, _info in HEALTH_TAGS_INFO.items():
    _lbl = (_info.get("label") or "").strip()
    if _lbl:
        HEALTH_TAG_LABELS[_tag] = _lbl

def build_usecase_from_tags(tags):
    labels = []
    for t in tags or []:
        lbl = HEALTH_TAG_LABELS.get(t)
        if lbl and lbl not in labels:
            labels.append(lbl)
    return "; ".join(labels)

# ---------- Helper: ki·ªÉm tra h·∫øt h√†ng ----------
def is_product_out_of_stock(p: dict) -> bool:
    """
    Quy ∆∞·ªõc hi·ªán t·∫°i:
    - N·∫øu c√≥ field in_stock = False ‚Üí h·∫øt h√†ng.
    - N·∫øu kh√¥ng c√≥ link (product_url/url) ‚Üí coi nh∆∞ t·∫°m h·∫øt h√†ng.
    """
    if isinstance(p.get("in_stock"), bool):
        return not p["in_stock"]
    url = (p.get("product_url") or p.get("url") or "").strip()
    return url == ""

# ---------- Helper chu·∫©n h√≥a & health tags ----------
def normalize_for_match(s: str) -> str:
    """Lower + b·ªè d·∫•u + b·ªè k√Ω t·ª± l·∫° ƒë·ªÉ so kh·ªõp alias/keyword."""
    import unicodedata
    if not s:
        return ""
    s = str(s).lower().strip()
    s = unicodedata.normalize("NFKD", s)
    s = "".join(ch for ch in s if not unicodedata.combining(ch))
    s = re.sub(r"[^a-z0-9\s]", " ", s)
    s = re.sub(r"\s+", " ", s).strip()
    return s

# Map keyword ‚Üí health_tag
_HEALTH_KEYWORD_TO_TAG_RAW = {
    "ti·ªÉu ƒë∆∞·ªùng": "tieu_duong",
    "dai thao duong": "tieu_duong",
    "ƒë√°i th√°o ƒë∆∞·ªùng": "tieu_duong",
    "duong huyet": "tieu_duong",
    "ƒë∆∞·ªùng huy·∫øt": "tieu_duong",

    "da day": "da_day",
    "d·∫° d√†y": "da_day",
    "bao tu": "da_day",
    "bao t·ª≠": "da_day",
    "trao nguoc": "da_day",
    "tr√†o ng∆∞·ª£c": "da_day",
    "o chua": "da_day",
    "·ª£ chua": "da_day",

    "tieu hoa": "tieu_hoa",
    "ti√™u h√≥a": "tieu_hoa",
    "tieu ho√°": "tieu_hoa",
    "tao bon": "tieu_hoa",
    "t√°o b√≥n": "tieu_hoa",

    "gan": "gan",
    "men gan": "gan",
    "gan nhiem mo": "gan",
    "gan nhi·ªÖm m·ª°": "gan",

    "xuong khop": "xuong_khop",
    "x∆∞∆°ng kh·ªõp": "xuong_khop",
    "dau khop": "xuong_khop",
    "ƒëau kh·ªõp": "xuong_khop",
    "gout": "xuong_khop",

    "huyet ap": "tim_mach",
    "huy·∫øt √°p": "tim_mach",
    "tim mach": "tim_mach",
    "tim m·∫°ch": "tim_mach",

    "thai doc": "thai_doc",
    "th·∫£i ƒë·ªôc": "thai_doc",
    "detox": "thai_doc",

    "ung thu": "ung_thu",
    "ung th∆∞": "ung_thu",
}

HEALTH_KEYWORD_TO_TAG = {
    normalize_for_match(k): v for k, v in _HEALTH_KEYWORD_TO_TAG_RAW.items()
}

# Chu·∫©n h√≥a symptoms_map t·ª´ file JSON: key (tri·ªáu ch·ª©ng) ‚Üí list health_tags
SYMPTOMS_MAP_NORM = {}
if isinstance(SYMPTOMS_MAP_RAW, dict):
    for raw_symptom, info in SYMPTOMS_MAP_RAW.items():
        tags = []
        if isinstance(info, dict):
            tags = info.get("health_tags", []) or []
        elif isinstance(info, list):
            tags = info
        key_norm = normalize_for_match(raw_symptom)
        if key_norm and tags:
            SYMPTOMS_MAP_NORM[key_norm] = tags

def extract_health_tags_from_text(text: str):
    """Tr√≠ch health_tags t·ª´ c√¢u m√¥ t·∫£ tri·ªáu ch·ª©ng/b·ªánh l√Ω."""
    nt = normalize_for_match(text)
    tags: set[str] = set()

    # 1) Theo tri·ªáu ch·ª©ng trong file JSON
    for sym_norm, tags_list in SYMPTOMS_MAP_NORM.items():
        if sym_norm and sym_norm in nt:
            for t in tags_list:
                if t:
                    tags.add(t)

    # 2) Theo keyword map c·ª©ng (b·ªï sung)
    for kw_norm, tag in HEALTH_KEYWORD_TO_TAG.items():
        if kw_norm and kw_norm in nt:
            tags.add(tag)

    return tags

# ---------- Alias & mapping s·∫£n ph·∫©m / combo ----------
def build_product_aliases(p: dict):
    aliases = set()
    name = p.get("name", "")
    code = str(p.get("code", "")).lstrip("#").strip()
    if code:
        p["code"] = code

    if name:
        aliases.add(name)
        aliases.add(name.lower())
        for part in re.findall(r"[\w\u00C0-\u017F\-\/]+", name):
            aliases.add(part)

    for a in p.get("aliases", []):
        if a:
            aliases.add(a)

    if code:
        aliases.add(code)

    aliases_clean = []
    for a in aliases:
        a2 = re.sub(r"\s+", " ", str(a)).strip()
        if a2:
            aliases_clean.append(a2)

    p["aliases"] = aliases_clean

def build_combo_aliases(c: dict):
    aliases = set()
    name = c.get("name", "")
    if name:
        aliases.add(name)
        aliases.add(name.lower())
        for part in re.findall(r"[\w\u00C0-\u017F\-\/]+", name):
            aliases.add(part)
    for a in c.get("aliases", []):
        if a:
            aliases.add(a)
    aliases_clean = []
    for a in aliases:
        a2 = re.sub(r"\s+", " ", str(a)).strip()
        if a2:
            aliases_clean.append(a2)
    c["aliases"] = aliases_clean

PRODUCT_MAP: dict[str, dict] = {}
PRODUCT_ALIAS_INDEX: dict[str, set[str]] = {}   # alias_norm ‚Üí set(code)

for p in PRODUCTS:
    build_product_aliases(p)
    code = p.get("code")
    if not code:
        continue

    current_tags = set(p.get("health_tags", []))
    text_for_tags = " ".join([
        p.get("name", ""),
        p.get("benefits_text", "") or p.get("benefits", "") or "",
        p.get("ingredients_text", "") or p.get("ingredients", "") or "",
        p.get("usage_text", "") or p.get("usage", "") or "",
    ])
    auto_tags = extract_health_tags_from_text(text_for_tags)
    all_tags = sorted(current_tags.union(auto_tags))
    if all_tags:
        p["health_tags"] = all_tags

    PRODUCT_MAP[code] = p

    for a in p["aliases"]:
        na = normalize_for_match(a)
        if not na:
            continue
        PRODUCT_ALIAS_INDEX.setdefault(na, set()).add(code)

# B·ªï sung alias t·ª´ file product_aliases.json (n·∫øu c√≥)
for alias_norm, codes in PRODUCT_ALIASES_BY_ALIAS.items():
    na = normalize_for_match(alias_norm)
    if not na:
        continue
    for code in codes:
        if not code:
            continue
        PRODUCT_ALIAS_INDEX.setdefault(na, set()).add(str(code))

COMBO_ID_MAP: dict[str, dict] = {}
COMBO_ALIAS_INDEX: dict[str, list[dict]] = {}   # alias_norm ‚Üí [combo]

for c in COMBOS:
    build_combo_aliases(c)
    cid = c.get("id") or normalize_for_match(c.get("name", "") or "")
    c["id"] = cid

    combo_tags = set(c.get("health_tags", []))
    text_for_tags = " ".join([
        c.get("name", ""),
        c.get("header_text", ""),
        c.get("duration_text", ""),
    ])
    combo_tags |= extract_health_tags_from_text(text_for_tags)

    for item in c.get("products", []):
        code = str(item.get("product_code", "")).lstrip("#").strip()
        item["product_code"] = code
        p = PRODUCT_MAP.get(code)
        if p:
            item.setdefault("name", p.get("name", ""))
            item.setdefault("price_text", p.get("price_text", ""))
            item.setdefault("product_url", p.get("product_url", ""))
            for t in p.get("health_tags", []):
                combo_tags.add(t)

    if combo_tags:
        c["health_tags"] = sorted(combo_tags)

    COMBO_ID_MAP[cid] = c

    for a in c["aliases"]:
        na = normalize_for_match(a)
        if not na:
            continue
        COMBO_ALIAS_INDEX.setdefault(na, []).append(c)

# ============== Telegram Keyboard ==============
MAIN_KEYBOARD = {
    "keyboard": [
        [
            {"text": "üß© Combo theo v·∫•n ƒë·ªÅ s·ª©c kh·ªèe"},
            {"text": "üîé Tra c·ª©u s·∫£n ph·∫©m"}
        ],
        [
            {"text": "üõí H∆∞·ªõng d·∫´n mua h√†ng"},
            {"text": "‚òéÔ∏è K·∫øt n·ªëi tuy·∫øn tr√™n"}
        ],
        [
            {"text": "üì¢ K√™nh & Fanpage"}
        ]
    ],
    "resize_keyboard": True,
    "one_time_keyboard": False
}

# ============== Flask app ==============
app = Flask(__name__)

# ============== Helper: g·ª≠i message Telegram ==============
def send_message(chat_id, text, reply_markup=None, parse_mode="Markdown"):
    payload = {
        "chat_id": chat_id,
        "text": text,
        "parse_mode": parse_mode
    }
    if reply_markup is not None:
        payload["reply_markup"] = json.dumps(reply_markup, ensure_ascii=False)

    url = f"{TELEGRAM_API}/sendMessage"
    try:
        requests.post(url, data=payload, timeout=10)
    except Exception as e:
        print("Error sending message:", e)

# ============== X∆∞ng h√¥ linh ho·∫°t ==============
def detect_user_tone(text: str) -> str | None:
    """
    ƒêo√°n style x∆∞ng h√¥ t·ª´ c√¢u c·ªßa ng∆∞·ªùi d√πng.
    Tr·∫£ v·ªÅ: 'anh_em', 'chi_em', 'ban_minh' ho·∫∑c None.
    """
    t = (text or "").lower()

    if "b·∫°n" in t or "ban oi" in t:
        return "ban_minh"

    if re.search(r"\banh\b", t) and "em" in t:
        return "anh_em"

    if re.search(r"\bch·ªã\b", t) or "chi" in t:
        if "em" in t:
            return "chi_em"

    return None

def get_pronouns_for_chat(chat_id: int) -> tuple[str, str]:
    """
    L·∫•y c√°ch x∆∞ng h√¥ ph√π h·ª£p cho chat n√†y.
    you_pronoun = ng∆∞·ªùi d√πng, me_pronoun = Bot.
    """
    ctx = CHAT_CONTEXT.get(chat_id, {})
    tone = ctx.get("tone", "default")

    if tone == "ban_minh":
        return "b·∫°n", "m√¨nh"
    if tone == "anh_em":
        return "anh", "em"
    if tone == "chi_em":
        return "ch·ªã", "em"

    return "anh/ch·ªã", "em"

def update_chat_context(chat_id: int, **kwargs):
    ctx = CHAT_CONTEXT.get(chat_id) or {}
    ctx.update(kwargs)
    CHAT_CONTEXT[chat_id] = ctx
    return ctx

# ============== Utility kh√°c ==============
def contains_any(text, keywords):
    text = text.lower()
    return any(k.lower() in text for k in keywords)

# ===== Feedback & correction =====
NEGATIVE_FEEDBACK_KEYWORDS = [
    "sai r·ªìi", "sai roi",
    "kh√¥ng ƒë√∫ng", "khong dung",
    "kh√¥ng ph·∫£i", "khong phai",
    "nh·∫ßm r·ªìi", "nham roi",
    "ko ƒë√∫ng", "ko dung",
    "ko ph·∫£i", "ko phai",
    "ch∆∞a ƒë√∫ng", "chua dung",
    "t∆∞ v·∫•n sai", "tu van sai",
    "sai combo", "sai s·∫£n ph·∫©m", "sai san pham",
    "kh√¥ng li√™n quan", "khong lien quan",
]

CORRECTION_KEYWORDS = [
    "ph·∫£i l√†", "phai la",
    "ƒë√∫ng l√†", "dung la",
    "ri√™ng s·∫£n ph·∫©m", "rieng san pham",
    "d√πng s·∫£n ph·∫©m", "dung san pham",
    "cho anh s·∫£n ph·∫©m", "cho em s·∫£n ph·∫©m",
]

def is_negative_feedback(text: str) -> bool:
    t = (text or "").lower()
    return any(kw in t for kw in NEGATIVE_FEEDBACK_KEYWORDS)

def seems_like_product_correction(text: str) -> bool:
    t = (text or "").lower()
    return any(kw in t for kw in CORRECTION_KEYWORDS)

def extract_code(text: str):
    text = text.strip()
    codes = re.findall(r"\b0\d{4,5}\b", text)
    return codes[0] if codes else None

# ============== T√¨m s·∫£n ph·∫©m / combo ==============
def find_best_products(text: str, limit: int = 5):
    """T√¨m s·∫£n ph·∫©m theo alias (name, m√£, alias m·ªü r·ªông)."""
    t = normalize_for_match(text)
    results = []
    seen = set()

    for alias_norm, codes in PRODUCT_ALIAS_INDEX.items():
        if alias_norm and alias_norm in t:
            for code in codes:
                if code not in seen and code in PRODUCT_MAP:
                    seen.add(code)
                    results.append(PRODUCT_MAP[code])
                    if len(results) >= limit:
                        return results

    if not results:
        tokens = t.split()
        for alias_norm, codes in PRODUCT_ALIAS_INDEX.items():
            if any(tok in alias_norm for tok in tokens):
                for code in codes:
                    if code not in seen and code in PRODUCT_MAP:
                        seen.add(code)
                        results.append(PRODUCT_MAP[code])
                        if len(results) >= limit:
                            return results

    return results

def find_products_by_health(text: str, limit: int = 5):
    tags_from_text = extract_health_tags_from_text(text)
    results = []
    seen = set()

    if tags_from_text:
        for p in PRODUCTS:
            p_tags = set(p.get("health_tags", []))
            if p_tags.intersection(tags_from_text):
                code = p.get("code")
                if code and code not in seen:
                    seen.add(code)
                    results.append(p)
                    if len(results) >= limit:
                        break

    if not results:
        results = find_best_products(text, limit=limit)

    return results

def find_best_combo(text: str, limit: int = 3):
    t = normalize_for_match(text)
    results = []
    seen = set()

    for alias_norm, combos in COMBO_ALIAS_INDEX.items():
        if alias_norm and alias_norm in t:
            for c in combos:
                cid = c.get("id")
                if cid not in seen:
                    seen.add(cid)
                    results.append(c)
                    if len(results) >= limit:
                        return results
    return results

def find_combo_by_health_keyword(text: str) -> dict | None:
    tags_from_text = extract_health_tags_from_text(text)
    best = None
    score_best = 0
    text_norm = normalize_for_match(text)

    for c in COMBOS:
        c_tags = set(c.get("health_tags", []))
        score = len(c_tags.intersection(tags_from_text)) if tags_from_text else 0
        for a in c.get("aliases", []):
            if normalize_for_match(a) in text_norm:
                score += 1
        if score > score_best:
            score_best = score
            best = c

    if not best:
        combos = find_best_combo(text, limit=1)
        best = combos[0] if combos else None

    return best

# ============== NLP ph√¢n t√≠ch c√¢u h·ªèi s·ª©c kh·ªèe ==============
def parse_user_query_with_ai(text: str) -> dict:
    base = {
        "symptoms": [],
        "goals": [],
        "need_meal_plan": False,
        "target": "auto",
        "raw_text": text,
    }
    if not client:
        return base

    try:
        resp = client.chat.completions.create(
            model="gpt-4.1-mini",
            temperature=0,
            response_format={"type": "json_object"},
            messages=[
                {
                    "role": "system",
                    "content": (
                        "B·∫°n l√† b·ªô ph√¢n t√≠ch c√¢u h·ªèi cho chatbot h·ªó tr·ª£ t∆∞ v·∫•n vi√™n th·ª±c ph·∫©m ch·ª©c nƒÉng.\n"
                        "Tr·∫£ v·ªÅ JSON:\n"
                        "{\n"
                        '  \"symptoms\": [...],\n'
                        '  \"goals\": [...],\n'
                        '  \"need_meal_plan\": true/false,\n'
                        '  \"target\": \"combo\" | \"product\" | \"info\" | \"auto\"\n'
                        "}\n"
                        "Ch·ªâ tr·∫£ JSON, kh√¥ng gi·∫£i th√≠ch th√™m."
                    ),
                },
                {"role": "user", "content": text},
            ],
        )
        content = resp.choices[0].message.content or ""
        data = json.loads(content)
    except Exception as e:
        print("parse_user_query_with_ai error:", e)
        return base

    parsed = dict(base)
    syms = data.get("symptoms")
    if isinstance(syms, list):
        parsed["symptoms"] = [str(s).strip() for s in syms if s]
    goals = data.get("goals")
    if isinstance(goals, list):
        parsed["goals"] = [str(g).strip() for g in goals if g]
    parsed["need_meal_plan"] = bool(data.get("need_meal_plan", False))
    target = str(data.get("target", "auto") or "auto").lower()
    if target not in ("combo", "product", "info", "auto"):
        target = "auto"
    parsed["target"] = target

    return parsed

def rank_combos_and_products(parsed: dict, limit_combos: int = 3, limit_products: int = 5) -> dict:
    text = parsed.get("raw_text") or ""
    text_norm = normalize_for_match(text)
    tags: set[str] = set()

    for s in parsed.get("symptoms") or []:
        tags.update(extract_health_tags_from_text(s))
    for g in parsed.get("goals") or []:
        tags.update(extract_health_tags_from_text(g))

    if not tags:
        tags.update(extract_health_tags_from_text(text))

    combo_scores: list[tuple[float, dict]] = []
    for c in COMBOS:
        c_tags = set(c.get("health_tags", []))
        if not c_tags:
            continue
        score = 0.0
        inter = c_tags.intersection(tags)
        if inter:
            score += 2.0 * len(inter)

        for a in c.get("aliases", []):
            na = normalize_for_match(a)
            if na and na in text_norm:
                score += 1.0
                break

        if score > 0:
            combo_scores.append((score, c))

    combo_scores.sort(key=lambda x: x[0], reverse=True)
    top_combos = [c for score, c in combo_scores[:limit_combos]]

    product_scores: list[tuple[float, dict]] = []
    for p in PRODUCTS:
        p_tags = set(p.get("health_tags", []))
        if not p_tags:
            continue
        score = 0.0

        inter = p_tags.intersection(tags)
        if inter:
            score += 2.0 * len(inter)

        for a in p.get("aliases", []):
            na = normalize_for_match(a)
            if na and na in text_norm:
                score += 1.0
                break

        code = str(p.get("code") or "").strip()
        if code and code in text_norm.replace(" ", ""):
            score += 3.0

        if is_product_out_of_stock(p):
            score -= 1.0

        if score > 0:
            product_scores.append((score, p))

    product_scores.sort(key=lambda x: x[0], reverse=True)
    top_products = [p for score, p in product_scores[:limit_products]]

    return {
        "tags": list(tags),
        "combos": top_combos,
        "products": top_products,
    }

# ===== lifestyle / ƒÉn u·ªëng =====
LIFESTYLE_KEYWORDS = [
    "ƒÉn u·ªëng", "an uong",
    "ch·∫ø ƒë·ªô ƒÉn", "che do an",
    "ki√™ng", "kieng", "ki√™ng g√¨", "kieng gi",
    "sinh ho·∫°t", "sinh hoat",
    "t·∫≠p luy·ªán", "tap luyen",
    "l·ªëi s·ªëng", "loi song",
    "u·ªëng n∆∞·ªõc", "uong nuoc",
    "ng·ªß ngh·ªâ", "ngu nghi"
]

def needs_lifestyle_advice(text: str, goals: list[str] | None = None) -> bool:
    t = (text or "").lower()
    if any(k in t for k in LIFESTYLE_KEYWORDS):
        return True
    if goals:
        for g in goals:
            gl = g.lower()
            if any(k in gl for k in LIFESTYLE_KEYWORDS):
                return True
    return False

def build_meal_plan_snippet(parsed: dict) -> str:
    if not parsed.get("need_meal_plan"):
        return ""
    lines = []
    lines.append("\nüçΩ *G·ª£i √Ω khung b·ªØa ƒÉn ƒëi k√®m:*")
    lines.append("- S√°ng: Y·∫øn m·∫°ch + tr·ª©ng/·ª©c g√† + 1 ph·∫ßn tr√°i c√¢y (t√°o/cam).")
    lines.append("- Tr∆∞a: ·ª®c g√†/c√° + khoai lang/g·∫°o l·ª©t + nhi·ªÅu rau xanh.")
    lines.append("- T·ªëi: C√°/ƒë·∫≠u ph·ª• + rau c·ªß + n·∫•m, h·∫°n ch·∫ø tinh b·ªôt nhanh.")
    lines.append("- U·ªëng 1.5‚Äì2L n∆∞·ªõc/ng√†y, h·∫°n ch·∫ø n∆∞·ªõc ng·ªçt c√≥ ƒë∆∞·ªùng, r∆∞·ª£u bia.")
    lines.append("- N·∫øu t·∫≠p luy·ªán: b·ªØa ph·ª• tr∆∞·ªõc/sau t·∫≠p (chu·ªëi + s·ªØa chua kh√¥ng ƒë∆∞·ªùng).")
    return "\n".join(lines)

def build_lifestyle_advice_with_ai(text: str, health_tags: list[str]) -> str:
    if not client:
        return ""
    try:
        tag_hint = ", ".join(health_tags) if health_tags else ""
        sys_prompt = (
            "B·∫°n l√† tr·ª£ l√Ω h·ªó tr·ª£ *t∆∞ v·∫•n vi√™n th·ª±c ph·∫©m ch·ª©c nƒÉng* t·∫°i Vi·ªát Nam.\n"
            "Nhi·ªám v·ª•: t√≥m t·∫Øt 3‚Äì6 g·∫°ch ƒë·∫ßu d√≤ng v·ªÅ *l·ªëi s·ªëng v√† ch·∫ø ƒë·ªô ƒÉn u·ªëng n√™n l∆∞u √Ω* "
            "cho kh√°ch h√†ng, d·ª±a tr√™n m√¥ t·∫£ t√¨nh tr·∫°ng m√† TVV g·ª≠i.\n"
            "- Kh√¥ng ch·∫©n ƒëo√°n b·ªánh, kh√¥ng k√™ ƒë∆°n, kh√¥ng n√™u t√™n thu·ªëc t√¢y ho·∫∑c li·ªÅu thu·ªëc.\n"
            "- Kh√¥ng ƒë∆∞·ª£c h·ª©a h·∫πn ch·ªØa kh·ªèi b·ªánh.\n"
            "- D√πng ng√¥n ng·ªØ d·ªÖ hi·ªÉu, ng·∫Øn g·ªçn, d·∫°ng g·∫°ch ƒë·∫ßu d√≤ng.\n"
            "- Lu√¥n c√≥ 1 g·∫°ch ƒë·∫ßu d√≤ng nh·∫Øc kh√°ch n√™n ƒëi kh√°m b√°c sƒ© n·∫øu tri·ªáu ch·ª©ng k√©o d√†i ho·∫∑c n·∫∑ng l√™n.\n"
        )

        user_prompt = (
            f"C√¢u h·ªèi / t√¨nh tr·∫°ng kh√°ch m√¥ t·∫£: ```{text}```\n"
            f"Health tags g·ª£i √Ω: {tag_hint}"
        )

        resp = client.chat.completions.create(
            model="gpt-4.1-mini",
            temperature=0.4,
            messages=[
                {"role": "system", "content": sys_prompt},
                {"role": "user", "content": user_prompt},
            ],
        )
        content = (resp.choices[0].message.content or "").strip()
        if not content:
            return ""
        return "\nüìù *M·ªôt s·ªë l∆∞u √Ω v·ªÅ l·ªëi s·ªëng & ƒÉn u·ªëng (tham kh·∫£o):*\n" + content
    except Exception as e:
        print("build_lifestyle_advice_with_ai error:", e)
        return ""

# ============== Format tr·∫£ l·ªùi ==============
def format_combo_answer(combo, you: str) -> str:
    name     = combo.get("name", "Combo")
    header   = combo.get("header_text", "")
    duration = combo.get("duration_text", "")

    lines = [f"*{name}*"]

    if header:
        lines.append(f"_M·ª•c ti√™u ch√≠nh:_ {header}")

    if duration:
        lines.append(f"‚è± *Th·ªùi gian khuy·∫øn ngh·ªã:* {duration}")

    combo_usecase = build_usecase_from_tags(combo.get("health_tags", []))
    if combo_usecase:
        lines.append(f"\nüéØ *Ph√π h·ª£p v·ªõi:* {combo_usecase}")

    lines.append("\nüß© *G·ªìm c√°c s·∫£n ph·∫©m:*")

    blocks = []
    for item in combo.get("products", []):
        code = (item.get("product_code") or "").strip()
        dose = (item.get("dose_text") or "").strip()

        p = PRODUCT_MAP.get(code, {}) if code else {}

        pname       = item.get("name")        or p.get("name")        or code
        price       = item.get("price_text")  or p.get("price_text", "")
        url         = item.get("product_url") or p.get("product_url", "")
        benefits    = item.get("benefits_text")    or p.get("benefits_text")    or p.get("benefits", "")
        usage       = item.get("usage_text")       or p.get("usage_text")       or p.get("usage", "")
        tags        = item.get("health_tags")      or p.get("health_tags", [])
        usecase     = build_usecase_from_tags(tags)

        b = f"‚Ä¢ *{pname}* ({code})"
        if price:
            b += f"\n  - Gi√° tham kh·∫£o: {price}"
        if benefits:
            b += f"\n  - C√¥ng d·ª•ng ch√≠nh: {benefits}"
        if usecase:
            b += f"\n  - D√πng nhi·ªÅu cho: {usecase}"
        if dose:
            b += f"\n  - Li·ªÅu d√πng g·ª£i √Ω trong combo: {dose}"
        elif usage:
            b += f"\n  - C√°ch d√πng g·ª£i √Ω: {usage}"

        if is_product_out_of_stock(p):
            b += "\n  - ‚ö†Ô∏è Hi·ªán s·∫£n ph·∫©m n√†y t·∫°m h·∫øt h√†ng tr√™n h·ªá th·ªëng, " \
                 "TVV c·∫ßn ki·ªÉm tra t·ªìn kho ho·∫∑c ch·ªçn s·∫£n ph·∫©m t∆∞∆°ng ƒë∆∞∆°ng."
        elif url:
            b += f"\n  - üîó Link tham kh·∫£o: {url}"

        blocks.append(b)

    lines.append("\n" + "\n\n".join(blocks))

    lines.append(
        "\n‚ö†Ô∏è ƒê√¢y l√† combo h·ªó tr·ª£, *kh√¥ng thay th·∫ø thu·ªëc ƒëi·ªÅu tr·ªã*. "
        f"{you.capitalize()} n√™n d·∫∑n kh√°ch duy tr√¨ ph√°c ƒë·ªì c·ªßa b√°c sƒ©, k·∫øt h·ª£p ƒÉn u·ªëng v√† v·∫≠n ƒë·ªông ph√π h·ª£p."
    )
    lines.append("\nüëâ TVV c√≥ th·ªÉ ch·ªânh l·∫°i c√¢u ch·ªØ cho ph√π h·ª£p v·ªõi c√°ch n√≥i chuy·ªán tr∆∞·ªõc khi g·ª≠i cho kh√°ch.")

    return "\n".join(lines)

def format_products_answer(products, you: str) -> str:
    if not products:
        return (
            "Hi·ªán t·∫°i em ch∆∞a t√¨m ƒë∆∞·ª£c s·∫£n ph·∫©m ph√π h·ª£p trong danh m·ª•c ·∫°. üôè\n"
            f"{you.capitalize()} g·ª≠i r√µ h∆°n t√™n s·∫£n ph·∫©m, m√£ s·∫£n ph·∫©m ho·∫∑c v·∫•n ƒë·ªÅ s·ª©c kh·ªèe c·ªßa kh√°ch gi√∫p em."
        )

    lines = ["D∆∞·ªõi ƒë√¢y l√† *m·ªôt s·ªë s·∫£n ph·∫©m ph√π h·ª£p* trong danh m·ª•c:\n"]
    for p in products[:5]:
        name        = p.get("name", "")
        code        = p.get("code", "")
        ingredients = p.get("ingredients_text", "") or p.get("ingredients", "")
        usage       = p.get("usage_text", "")       or p.get("usage", "")
        benefits    = p.get("benefits_text", "")    or p.get("benefits", "")
        url         = p.get("product_url", "")      or p.get("url", "")
        price       = p.get("price_text", "")       or p.get("price", "")
        tags        = p.get("health_tags", [])
        usecase     = build_usecase_from_tags(tags)

        block = f"*{name}* ({code})"
        if price:
            block += f"\n- Gi√° tham kh·∫£o: {price}"
        if benefits:
            block += f"\n- L·ª£i √≠ch ch√≠nh: {benefits}"
        if usecase:
            block += f"\n- D√πng trong c√°c tr∆∞·ªùng h·ª£p: {usecase}"
        if ingredients:
            block += f"\n- Th√†nh ph·∫ßn n·ªïi b·∫≠t: {ingredients}"
        if usage:
            block += f"\n- C√°ch d√πng g·ª£i √Ω: {usage}"
        if is_product_out_of_stock(p):
            block += "\n- ‚ö†Ô∏è S·∫£n ph·∫©m n√†y hi·ªán t·∫°m h·∫øt h√†ng tr√™n h·ªá th·ªëng, TVV c·∫ßn ki·ªÉm tra t·ªìn kho ho·∫∑c ch·ªçn s·∫£n ph·∫©m kh√°c."
        elif url:
            block += f"\n- üîó Link s·∫£n ph·∫©m: {url}"
        lines.append(block)
        lines.append("")

    lines.append(
        "üëâ TVV h√£y l·ª±a ch·ªçn s·∫£n ph·∫©m ph√π h·ª£p nh·∫•t v·ªõi t√¨nh tr·∫°ng c·ª• th·ªÉ c·ªßa kh√°ch, "
        "v√† lu√¥n nh·∫Øc kh√°ch ƒë·ªçc k·ªπ h∆∞·ªõng d·∫´n s·ª≠ d·ª•ng, tham kh·∫£o √Ω ki·∫øn b√°c sƒ© khi c·∫ßn."
    )
    return "\n".join(lines)

def format_product_by_code(code: str, you: str) -> str:
    p = PRODUCT_MAP.get(code)
    if not p:
        return f"Em ch∆∞a t√¨m th·∫•y m√£ s·∫£n ph·∫©m n√†y ·∫°. {you.capitalize()} ki·ªÉm tra l·∫°i gi√∫p em m√£ s·ªë nh√©. üôè"

    name        = p.get("name", "")
    ingredients = p.get("ingredients_text", "") or p.get("ingredients", "")
    usage       = p.get("usage_text", "")       or p.get("usage", "")
    benefits    = p.get("benefits_text", "")    or p.get("benefits", "")
    url         = p.get("product_url", "")      or p.get("url", "")
    price       = p.get("price_text", "")       or p.get("price", "")
    tags        = p.get("health_tags", [])
    usecase     = build_usecase_from_tags(tags)

    lines = [f"*{name}* ({code})"]
    if price:
        lines.append(f"- Gi√° tham kh·∫£o: {price}")
    if benefits:
        lines.append(f"- L·ª£i √≠ch ch√≠nh: {benefits}")
    if usecase:
        lines.append(f"- D√πng trong c√°c tr∆∞·ªùng h·ª£p: {usecase}")
    if ingredients:
        lines.append(f"- Th√†nh ph·∫ßn n·ªïi b·∫≠t: {ingredients}")
    if usage:
        lines.append(f"- C√°ch d√πng g·ª£i √Ω: {usage}")
    if is_product_out_of_stock(p):
        lines.append("- ‚ö†Ô∏è S·∫£n ph·∫©m n√†y hi·ªán t·∫°m h·∫øt h√†ng tr√™n h·ªá th·ªëng, TVV c·∫ßn ki·ªÉm tra t·ªìn kho ho·∫∑c tham kh·∫£o s·∫£n ph·∫©m kh√°c.")
    elif url:
        lines.append(f"- üîó Link s·∫£n ph·∫©m: {url}")
    lines.append(
        "\nüëâ TVV c√≥ th·ªÉ ch·ªânh s·ª≠a c√¢u ch·ªØ cho ph√π h·ª£p v·ªõi kh√°ch, "
        "v√† nh·∫Øc kh√°ch ƒë·ªçc k·ªπ h∆∞·ªõng d·∫´n s·ª≠ d·ª•ng, tham kh·∫£o √Ω ki·∫øn b√°c sƒ© khi c·∫ßn."
    )
    return "\n".join(lines)

# ============== C√°c c√¢u menu / c·ªë ƒë·ªãnh ==============
def answer_start(you: str, me: str):
    return (
        f"*Ch√†o {you}, {me} l√† Tr·ª£ l√Ω AI h·ªó tr·ª£ kinh doanh & s·∫£n ph·∫©m ƒë√¢y ·∫°!* ü§ñ\n\n"
        f"{you.capitalize()} c√≥ th·ªÉ h·ªèi {me} v·ªÅ:\n"
        "‚Ä¢ V·∫•n ƒë·ªÅ s·ª©c kh·ªèe: _\"Kh√°ch b·ªã ti·ªÉu ƒë∆∞·ªùng th√¨ d√πng combo n√†o?\"_\n"
        "‚Ä¢ Th√¥ng tin s·∫£n ph·∫©m: _\"Cho em th√†nh ph·∫ßn, c√°ch d√πng c·ªßa m√£ 070728\"_\n"
        "‚Ä¢ Quy tr√¨nh mua h√†ng: _\"H∆∞·ªõng d·∫´n mua h√†ng / thanh to√°n th·∫ø n√†o?\"_\n"
        "‚Ä¢ Nh·ªù tuy·∫øn tr√™n: _\"C√¢u n√†y kh√≥, cho em xin k·∫øt n·ªëi leader?\"_\n\n"
        "Ho·∫∑c b·∫•m c√°c n√∫t menu b√™n d∆∞·ªõi ƒë·ªÉ thao t√°c nhanh nh√©. ‚ù§Ô∏è"
    )

def answer_menu_combo(you: str, me: str):
    return (
        "üß© *Combo theo v·∫•n ƒë·ªÅ s·ª©c kh·ªèe*\n\n"
        f"{you.capitalize()} h√£y g√µ c√¢u d·∫°ng:\n"
        "- \"Kh√°ch *ti·ªÉu ƒë∆∞·ªùng* th√¨ d√πng combo n√†o?\"\n"
        "- \"Kh√°ch b·ªã *c∆° x∆∞∆°ng kh·ªõp* ƒëau nhi·ªÅu th√¨ t∆∞ v·∫•n combo g√¨?\"\n"
        "- \"Kh√°ch b·ªã *huy·∫øt √°p, tim m·∫°ch* th√¨ n√™n d√πng g√¨?\""
    )

def answer_menu_product_search(you: str, me: str):
    return (
        "üîé *Tra c·ª©u s·∫£n ph·∫©m*\n\n"
        f"{you.capitalize()} c√≥ th·ªÉ h·ªèi:\n"
        "- \"Cho em info s·∫£n ph·∫©m *ANTISWEET*?\"\n"
        "- \"Th√†nh ph·∫ßn, c√°ch d√πng c·ªßa m√£ *070728* l√† g√¨?\"\n"
        "- \"S·∫£n ph·∫©m n√†o h·ªó tr·ª£ *ti·ªÉu ƒë∆∞·ªùng / men gan / x∆∞∆°ng kh·ªõp*?\""
    )

def answer_buy_payment(you: str, me: str):
    lines = []
    lines.append("*H∆∞·ªõng d·∫´n mua h√†ng & thanh to√°n* üõí")
    lines.append("\n1Ô∏è‚É£ *C√°ch mua h√†ng:*")
    lines.append(f"- ƒê·∫∑t tr·ª±c ti·∫øp tr√™n website: {LINK_WEBSITE}")
    lines.append("- Nh·ªù TVV t·∫°o ƒë∆°n h√†ng tr√™n h·ªá th·ªëng.")
    lines.append("- G·ªçi Hotline ƒë·ªÉ ƒë∆∞·ª£c h·ªó tr·ª£ t·∫°o ƒë∆°n.")
    lines.append("\n2Ô∏è‚É£ *C√°c b∆∞·ªõc ƒë·∫∑t tr√™n website (g·ª£i √Ω):*")
    lines.append("   1. Truy c·∫≠p website.")
    lines.append("   2. Ch·ªçn s·∫£n ph·∫©m ‚Üí b·∫•m *‚ÄúTh√™m v√†o gi·ªè‚Äù*.")    
    lines.append("   3. V√†o *Gi·ªè h√†ng* ‚Üí ki·ªÉm tra s·∫£n ph·∫©m.")
    lines.append("   4. B·∫•m *‚ÄúThanh to√°n‚Äù* ‚Üí nh·∫≠p th√¥ng tin nh·∫≠n h√†ng.")
    lines.append("   5. Ch·ªçn h√¨nh th·ª©c thanh to√°n ph√π h·ª£p.")
    lines.append("\n3Ô∏è‚É£ *H√¨nh th·ª©c thanh to√°n th∆∞·ªùng d√πng:*")
    lines.append("- üíµ Thanh to√°n khi nh·∫≠n h√†ng (COD).")
    lines.append("- üí≥ Chuy·ªÉn kho·∫£n ng√¢n h√†ng (theo s·ªë TK ch√≠nh th·ª©c c·ªßa c√¥ng ty).")
    lines.append("- üì± Thanh to√°n online (QR, v√≠ ƒëi·ªán t·ª≠‚Ä¶) n·∫øu c√≥.")
    return "\n".join(lines)

def answer_business_escalation(you: str, me: str):
    return (
        "*K·∫øt n·ªëi tuy·∫øn tr√™n khi g·∫∑p c√¢u h·ªèi kh√≥* ‚òéÔ∏è\n\n"
        f"{you.capitalize()} h√£y g·ª≠i ti·∫øp *1 tin nh·∫Øn n·ªØa* m√¥ t·∫£ r√µ:\n"
        "- C√¢u h·ªèi / t√¨nh hu·ªëng c·ª• th·ªÉ c·ªßa kh√°ch\n"
        "- Ph∆∞∆°ng √°n {you} ƒëang ph√¢n v√¢n ho·∫∑c ƒë√£ tr·∫£ l·ªùi th·ª≠\n"
        "- M·ª©c ƒë·ªô g·∫•p (vd: c·∫ßn h·ªó tr·ª£ trong h√¥m nay)\n\n"
        "Ngay sau tin nh·∫Øn ƒë√≥, em s·∫Ω *chuy·ªÉn nguy√™n vƒÉn* cho tuy·∫øn tr√™n ƒë·ªÉ h·ªó tr·ª£.\n"
        f"N·∫øu th·∫≠t s·ª± g·∫•p, {you} c√≥ th·ªÉ g·ªçi th√™m Hotline: *{HOTLINE_TUYEN_TREN}*."
    )

def answer_channels(you: str, me: str):
    return (
        "*K√™nh & Fanpage ch√≠nh th·ª©c c·ªßa c√¥ng ty* üì¢\n\n"
        f"- üì∫ K√™nh Telegram: {LINK_KENH_TELEGRAM}\n"
        f"- üëç Fanpage Facebook: {LINK_FANPAGE}\n"
        f"- üåê Website: {LINK_WEBSITE}\n\n"
        "üëâ TVV n√™n ∆∞u ti√™n g·ª≠i kh√°ch c√°c ƒë∆∞·ªùng link ch√≠nh th·ª©c n√†y."
    )

def answer_fallback(you: str, me: str):
    return (
        "Hi·ªán t·∫°i em ch∆∞a hi·ªÉu r√µ c√¢u h·ªèi ho·∫∑c ch∆∞a c√≥ d·ªØ li·ªáu cho n·ªôi dung n√†y ·∫°. üôè\n\n"
        f"{you.capitalize()} c√≥ th·ªÉ:\n"
        "- M√¥ t·∫£ *c·ª• th·ªÉ h∆°n* t√¨nh tr·∫°ng c·ªßa kh√°ch, ho·∫∑c\n"
        "- H·ªèi d·∫°ng: \"Kh√°ch b·ªã *ti·ªÉu ƒë∆∞·ªùng*...\", \"Kh√°ch b·ªã *ƒëau d·∫° d√†y*...\", "
        "\"*C√°ch mua h√†ng*?\", \"*Thanh to√°n th·∫ø n√†o*?\", ho·∫∑c\n"
        "- B·∫•m n√∫t *K·∫øt n·ªëi tuy·∫øn tr√™n* ƒë·ªÉ em h∆∞·ªõng d·∫´n li√™n h·ªá leader."
    )

def answer_smalltalk_thanks(you: str, me: str):
    return (
        f"D·∫° {me} c·∫£m ∆°n {you} nhi·ªÅu ·∫°. üôè\n"
        f"N·∫øu {you} c·∫ßn {me} g·ª£i √Ω th√™m combo ho·∫∑c s·∫£n ph·∫©m cho ca kh√°c, c·ª© nh·∫Øn cho {me} b·∫•t k·ª≥ l√∫c n√†o nh√©. ‚ù§Ô∏è"
    )

# ============== Logging l√™n Google Sheets ==============
def log_to_sheet(payload: dict):
    if not LOG_SHEET_WEBHOOK_URL:
        return
    try:
        requests.post(LOG_SHEET_WEBHOOK_URL, json=payload, timeout=5)
    except Exception as e:
        print("Error log_to_sheet:", e)

# ============== AI: m∆∞·ª£t h√≥a c√¢u tr·∫£ l·ªùi ==============
def polish_answer_with_ai(answer: str) -> str:
    if not client or not ENABLE_AI_POLISH:
        return answer
    try:
        sys_prompt = (
            "B·∫°n l√† tr·ª£ l√Ω vi·∫øt l·∫°i c√¢u tr·∫£ l·ªùi cho ƒë·ªôi t∆∞ v·∫•n vi√™n s·∫£n ph·∫©m s·ª©c kh·ªèe t·∫°i Vi·ªát Nam.\n"
            "- Gi·ªØ nguy√™n *c√°ch x∆∞ng h√¥* ƒë√£ c√≥ trong n·ªôi dung (anh, ch·ªã, b·∫°n, m√¨nh, em...), KH√îNG t·ª± ƒë·ªïi.\n"
            "- Gi·ªØ n·ªôi dung chuy√™n m√¥n, *kh√¥ng ƒë∆∞·ª£c th√™m claim ho·∫∑c l·ª£i √≠ch m·ªõi* ngo√†i nh·ªØng g√¨ ƒë√£ c√≥.\n"
            "- Gi·ªØ nguy√™n t√™n s·∫£n ph·∫©m, m√£ s·∫£n ph·∫©m, gi√° v√† ƒë∆∞·ªùng link.\n"
            "- ∆Øu ti√™n vi·∫øt ng·∫Øn g·ªçn, chia √Ω b·∫±ng g·∫°ch ƒë·∫ßu d√≤ng, tr√°nh ƒëo·∫°n vƒÉn qu√° d√†i.\n"
            "- N·∫øu n·ªôi dung ƒë√£ r√µ, ch·ªâ ch·ªânh s·ª≠a c√¢u ch·ªØ cho t·ª± nhi√™n, kh√¥ng c·∫ßn k√©o d√†i th√™m."
        )
        resp = client.chat.completions.create(
            model="gpt-4.1-mini",
            temperature=0.4,
            messages=[
                {"role": "system", "content": sys_prompt},
                {"role": "user", "content": answer}
            ]
        )
        new_answer = resp.choices[0].message.content.strip()
        return new_answer or answer
    except Exception as e:
        print("Error polish_answer_with_ai:", e)
        return answer

# ============== Orchestrator s·ª©c kh·ªèe ==============
def orchestrate_health_answer(text: str, intent: str, you: str):
    """
    Tr·∫£ v·ªÅ: reply_text, matched_combo, matched_product, parsed, ranking
    """
    parsed = parse_user_query_with_ai(text)
    ranking = rank_combos_and_products(parsed)
    combos = ranking.get("combos") or []
    products = ranking.get("products") or []

    reply = ""
    matched_combo = None
    matched_product = None

    if intent == "combo_health":
        if combos:
            matched_combo = combos[0]
            reply = format_combo_answer(matched_combo, you)
        elif products:
            matched_product = products[0]
            reply = format_products_answer(products, you)
        else:
            combo_old = find_combo_by_health_keyword(text)
            if combo_old:
                matched_combo = combo_old
                reply = format_combo_answer(combo_old, you)
            else:
                products_old = find_products_by_health(text)
                if products_old:
                    matched_product = products_old[0]
                reply = format_products_answer(products_old, you)

    elif intent == "health_products":
        products = find_products_by_health(text)
        reply    = format_products_answer(products, you)

    elif intent == "product_correction":
        products = find_best_products(text, limit=3)
        if products:
            reply = format_products_answer([products[0]], you)
            reply += "\n\nüíæ Em ƒë√£ ghi nh·ªõ s·∫£n ph·∫©m n√†y l√† l·ª±a ch·ªçn ∆∞u ti√™n cho nh·ªØng ca t∆∞∆°ng t·ª± l·∫ßn sau ·∫°."
            matched_product = products[0]
        else:
            reply = (
                "Em ch∆∞a t√¨m ƒë∆∞·ª£c r√µ s·∫£n ph·∫©m/combo m√† anh/ch·ªã v·ª´a nh·∫Øc t·ªõi ·∫°. üôè\n"
                "Anh/ch·ªã g·ª≠i gi√∫p em t√™n ho·∫∑c *m√£ s·∫£n ph·∫©m/combo* r√µ h∆°n ƒë·ªÉ em ghi nh·ªõ ch√≠nh x√°c nh√©."
            )

    elif intent == "product_info":
        if products:
            matched_product = products[0]
            reply = format_products_answer(products, you)
        else:
            products_old = find_best_products(text)
            if products_old:
                matched_product = products_old[0]
            reply = format_products_answer(products_old, you)

    # Meal plan & lifestyle
    meal_plan = build_meal_plan_snippet(parsed)
    lifestyle = ""
    if needs_lifestyle_advice(text, parsed.get("goals")):
        lifestyle = build_lifestyle_advice_with_ai(text, ranking.get("tags") or [])

    if meal_plan:
        reply = f"{reply}{meal_plan}"
    if lifestyle:
        reply = f"{reply}\n\n{lifestyle}"

    return reply, matched_combo, matched_product, parsed, ranking

# ============== AI: ph√¢n lo·∫°i intent ==============
INTENT_LABELS = [
    "start",
    "buy_payment",
    "business_escalation",
    "business_escalation_detail",
    "channels",
    "combo_health",
    "product_info",
    "product_by_code",
    "health_products",
    "menu_combo",
    "menu_product_search",
    "menu_buy_payment",
    "menu_business_escalation",
    "menu_channels",
    "smalltalk_thanks",
    "fallback"
]

def classify_intent_ai(text: str):
    if not client:
        return None
    try:
        resp = client.chat.completions.create(
            model="gpt-4.1-mini",
            temperature=0,
            messages=[
                {
                    "role": "system",
                    "content": (
                        "You are an intent classifier for a Telegram bot helping health product advisors.\n"
                        "Return ONLY ONE of these labels:\n"
                        f"{', '.join(INTENT_LABELS)}\n\n"
                        "Meaning:\n"
                        "- start: greeting or /start\n"
                        "- buy_payment: how to buy/pay/order\n"
                        "- business_escalation: hard business/commission/policy questions\n"
                        "- business_escalation_detail: follow-up message describing the hard question for upline\n"
                        "- channels: official channels, fanpage, website\n"
                        "- combo_health: which combo for a health problem\n"
                        "- product_info: ask about a product by name or description\n"
                        "- product_by_code: ask using a product code (e.g. 070728)\n"
                        "- health_products: ask for products for a health issue (not necessarily a combo)\n"
                        "- menu_* : when pressing menu buttons with those meanings\n"
                        "- smalltalk_thanks: thanks / closing messages\n"
                        "- fallback: anything else\n"
                        "Answer with ONLY the label, no explanation."
                    )
                },
                {"role": "user", "content": text}
            ]
        )
        label = resp.choices[0].message.content.strip().lower()
        if label in INTENT_LABELS:
            return label
    except Exception as e:
        print("Error classify_intent_ai:", e)
    return None

def classify_intent_rules(text: str):
    t = text.lower().strip()

    # smalltalk c·∫£m ∆°n / k·∫øt th√∫c
    if any(kw in t for kw in [
        "c·∫£m ∆°n", "cam on", "thanks", "thank you", "ok em", "oke em",
        "ok, c·∫£m ∆°n em", "ok c·∫£m ∆°n em"
    ]):
        return "smalltalk_thanks"

    if "combo theo v·∫•n ƒë·ªÅ" in t:
        return "menu_combo"
    if "tra c·ª©u s·∫£n ph·∫©m" in t:
        return "menu_product_search"
    if "h∆∞·ªõng d·∫´n mua h√†ng" in t:
        return "menu_buy_payment"
    if "k·∫øt n·ªëi tuy·∫øn tr√™n" in t:
        return "menu_business_escalation"
    if "k√™nh & fanpage" in t or "k√™nh & fan" in t or "k√™nh v√† fanpage" in t:
        return "menu_channels"

    if t.startswith("/start") or "b·∫Øt ƒë·∫ßu" in t or "hello" in t:
        return "start"

    code = extract_code(t)
    if code and code in PRODUCT_MAP:
        return "product_by_code"

    if contains_any(t, ["mua h√†ng", "ƒë·∫∑t h√†ng", "ƒë·∫∑t mua", "thanh to√°n", "tr·∫£ ti·ªÅn", "ship", "giao h√†ng"]):
        return "buy_payment"

    if contains_any(t, ["tuy·∫øn tr√™n", "leader", "sponsor", "upline", "kh√≥ tr·∫£ l·ªùi", "h·ªèi gi√∫p"]):
        return "business_escalation"

    if contains_any(t, ["k√™nh", "kenh", "fanpage", "facebook", "page", "k√™nh ch√≠nh th·ª©c"]):
        return "channels"

    if contains_any(t, [
        "ti·ªÉu ƒë∆∞·ªùng", "ƒë√°i th√°o ƒë∆∞·ªùng", "ƒë∆∞·ªùng huy·∫øt",
        "d·∫° d√†y", "bao t·ª≠", "tr√†o ng∆∞·ª£c", "·ª£ chua",
        "c∆° x∆∞∆°ng kh·ªõp", "ƒëau kh·ªõp", "gout",
        "huy·∫øt √°p", "tim m·∫°ch",
        "gan", "men gan", "gan nhi·ªÖm m·ª°",
        "ti√™u h√≥a", "r·ªëi lo·∫°n ti√™u h√≥a", "t√°o b√≥n"
    ]):
        return "combo_health"

    if seems_like_product_correction(text):
        return "product_correction"

    if contains_any(t, ["th√†nh ph·∫ßn", "t√°c d·ª•ng", "l·ª£i √≠ch", "c√°ch d√πng", "c√¥ng d·ª•ng", "u·ªëng nh∆∞ th·∫ø n√†o"]):
        return "product_info"

    if find_best_combo(t):
        return "combo_health"
    if find_best_products(t):
        return "product_info"

    return "fallback"

def classify_intent(text: str):
    label = classify_intent_ai(text)
    if label:
        return label
    return classify_intent_rules(text)

# ============== Webhook ch√≠nh ==============
@app.route("/webhook", methods=["POST"])
def webhook():
    update = request.get_json(force=True)
    message = update.get("message") or update.get("edited_message")
    if not message:
        return jsonify(ok=True)

    chat_id   = message["chat"]["id"]
    text      = message.get("text", "") or ""
    from_user = message.get("from", {}) or {}
    user_name = (from_user.get("first_name", "") + " " +
                 from_user.get("last_name", "")).strip() or from_user.get("username", "")

    # ===== Tin nh·∫Øn t·ª´ nh√≥m tuy·∫øn tr√™n =====
    if UPLINE_CHAT_ID and str(chat_id) == str(UPLINE_CHAT_ID) and text.strip():
        target_chat_id = None
        reply_body = None

        m = re.match(r"^/reply\s+(-?\d+)\s+(.+)", text.strip(), re.DOTALL | re.IGNORECASE)
        if m:
            target_chat_id = int(m.group(1))
            reply_body = m.group(2).strip()
        else:
            reply_msg = message.get("reply_to_message") or {}
            base_text = reply_msg.get("text") or ""
            m2 = re.search(r"chat_id:\s*`(-?\d+)`", base_text)
            if m2:
                target_chat_id = int(m2.group(1))
                reply_body = text.strip()

        if target_chat_id and reply_body:
            tvv_reply = f"*Tr·∫£ l·ªùi t·ª´ tuy·∫øn tr√™n:* üëá\n\n{reply_body}"
            tvv_reply = polish_answer_with_ai(tvv_reply)
            send_message(target_chat_id, tvv_reply, reply_markup=MAIN_KEYBOARD)

            log_payload = {
                "chat_id": target_chat_id,
                "user_name": user_name,
                "text": reply_body,
                "intent": "upline_reply",
                "matched_combo_id": "",
                "matched_combo_name": "",
                "matched_product_code": "",
                "matched_product_name": "",
                "upline_name": user_name,
                "from_upline_chat_id": chat_id,
            }
            log_to_sheet(log_payload)

        return jsonify(ok=True)

    # ===== Tin nh·∫Øn t·ª´ TVV =====
    if not text:
        send_message(chat_id, "Hi·ªán t·∫°i em ch·ªâ hi·ªÉu tin nh·∫Øn d·∫°ng text th√¥i ·∫°. üôè", reply_markup=MAIN_KEYBOARD)
        return jsonify(ok=True)

    # C·∫≠p nh·∫≠t style x∆∞ng h√¥ theo c√¢u hi·ªán t·∫°i (n·∫øu ƒëo√°n ƒë∆∞·ª£c)
    tone = detect_user_tone(text)
    if tone:
        update_chat_context(chat_id, tone=tone)

    you, me = get_pronouns_for_chat(chat_id)

    # N·∫øu ƒëang ch·ªù m√¥ t·∫£ cho tuy·∫øn tr√™n
    if ESCALATION_PENDING.get(chat_id):
        ESCALATION_PENDING.pop(chat_id, None)

        if UPLINE_CHAT_ID:
            notify = (
                "üîî *Y√äU C·∫¶U H·ªñ TR·ª¢ TUY·∫æN TR√äN*\n\n"
                f"- T·ª´ TVV: *{user_name}* (chat_id: `{chat_id}`)\n"
                f"- N·ªôi dung:\n{text}"
            )
            try:
                send_message(UPLINE_CHAT_ID, notify)
            except Exception as e:
                print("Error forward to upline:", e)

        confirm = (
            f"Em ƒë√£ ghi nh·∫≠n v√† *chuy·ªÉn n·ªôi dung n√†y cho tuy·∫øn tr√™n* r·ªìi ·∫°. ‚úÖ\n"
            f"N·∫øu {you} c·∫ßn g·∫•p, c√≥ th·ªÉ g·ªçi th√™m Hotline: *{HOTLINE_TUYEN_TREN}*.\n"
            "Khi tuy·∫øn tr√™n ph·∫£n h·ªìi, anh/ch·ªã nh·ªõ c·∫≠p nh·∫≠t l·∫°i cho kh√°ch nh√©."
        )
        confirm = polish_answer_with_ai(confirm)
        send_message(chat_id, confirm, reply_markup=MAIN_KEYBOARD)

        log_payload = {
            "chat_id": chat_id,
            "user_name": user_name,
            "text": text,
            "intent": "business_escalation_detail",
            "matched_combo_id": "",
            "matched_combo_name": "",
            "matched_product_code": "",
            "matched_product_name": "",
        }
        log_to_sheet(log_payload)

        return jsonify(ok=True)

    # ===== N·∫øu ƒë√¢y l√† ph·∫£n h·ªìi ch√™ sai ‚Üí xin combo/s·∫£n ph·∫©m chu·∫©n ƒë·ªÉ h·ªçc =====
    if is_negative_feedback(text):
        ctx = CHAT_CONTEXT.get(chat_id, {})
        last_combo_name   = ctx.get("last_matched_combo_name") or ""
        last_product_name = ctx.get("last_matched_product_name") or ""

        hint = ""
        if last_combo_name:
            hint = f" (l√∫c n√£y {me} ƒëang ∆∞u ti√™n combo *{last_combo_name}*)"
        elif last_product_name:
            hint = f" (l√∫c n√£y {me} ƒëang ∆∞u ti√™n s·∫£n ph·∫©m *{last_product_name}*)"

        reply = (
            f"D·∫° {me} xin l·ªói, g·ª£i √Ω v·ª´a r·ªìi ch∆∞a ƒë√∫ng √Ω {you}{hint} ·∫°. üôè\n\n"
            f"ƒê·ªÉ {me} h·ªçc ƒë√∫ng theo ph√°c ƒë·ªì th·ª±c t·∫ø c·ªßa c√¥ng ty, "
            f"{you} cho {me} lu√¥n *combo ho·∫∑c s·∫£n ph·∫©m m√† b√™n m√¨nh ƒëang d√πng hi·ªáu qu·∫£ nh·∫•t cho ca n√†y* nh√©.\n"
            "Ch·ªâ c·∫ßn g·ª≠i cho em:\n"
            "‚Ä¢ T√™n combo/s·∫£n ph·∫©m (ho·∫∑c m√£)\n"
            "‚Ä¢ N·∫øu c√≥ ph√¢n lo·∫°i (nh·∫π/v·ª´a/n·∫∑ng ho·∫∑c theo ng√¢n s√°ch) th√¨ ghi th√™m gi√∫p em ·∫°.\n\n"
            f"L·∫ßn sau g·∫∑p ca t∆∞∆°ng t·ª±, {me} s·∫Ω ∆∞u ti√™n ƒë√∫ng combo/s·∫£n ph·∫©m ƒë√≥ ƒë·ªÉ h·ªó tr·ª£ {you} nhanh v√† chu·∫©n h∆°n."
        )

        reply = polish_answer_with_ai(reply)
        send_message(chat_id, reply, reply_markup=MAIN_KEYBOARD)

        log_payload = {
            "chat_id": chat_id,
            "user_name": user_name,
            "text": text,
            "bot_reply": reply,
            "intent": "user_feedback_negative",
            "parsed_symptoms": [],
            "parsed_goals": [],
            "parsed_target": "",
            "need_meal_plan": False,
            "health_tags": [],
            "matched_combo_id": "",
            "matched_combo_name": "",
            "matched_product_code": "",
            "matched_product_name": "",
            "ranked_combos": [],
            "ranked_products": [],
            "final_combo_id": "",
            "final_product_code": "",
            "feedback": "",
        }
        log_to_sheet(log_payload)
        return jsonify(ok=True)

    # TVV ch·ªânh l·∫°i: n√™u r√µ s·∫£n ph·∫©m ƒë√∫ng
    if seems_like_product_correction(text):
        products = find_best_products(text, limit=3)
        if products:
            main_product = products[0]
            reply = format_products_answer([main_product], you)
            reply = polish_answer_with_ai(reply)
            send_message(chat_id, reply, reply_markup=MAIN_KEYBOARD)

            matched_product_code = main_product.get("code", "")
            matched_product_name = main_product.get("name", "")

            update_chat_context(
                chat_id,
                last_intent="product_correction",
                last_text=text,
                last_reply=reply,
                last_matched_combo_id="",
                last_matched_combo_name="",
                last_matched_product_code=matched_product_code,
                last_matched_product_name=matched_product_name,
            )

            log_payload = {
                "chat_id": chat_id,
                "user_name": user_name,
                "text": text,
                "intent": "product_correction",
                "matched_combo_id": "",
                "matched_combo_name": "",
                "matched_product_code": matched_product_code,
                "matched_product_name": matched_product_name,
            }
            log_to_sheet(log_payload)

            return jsonify(ok=True)

    # ===== B√¨nh th∆∞·ªùng: ph√¢n lo·∫°i intent =====
    intent = classify_intent(text)

    matched_combo_id      = ""
    matched_combo_name    = ""
    matched_product_code  = ""
    matched_product_name  = ""

    parsed_for_log  = None
    ranking_for_log = None

    # X·ª≠ l√Ω intent
    if intent == "start":
        reply = answer_start(you, me)

    elif intent == "menu_combo":
        reply = answer_menu_combo(you, me)

    elif intent == "menu_product_search":
        reply = answer_menu_product_search(you, me)

    elif intent in ("menu_buy_payment", "buy_payment"):
        reply = answer_buy_payment(you, me)

    elif intent in ("menu_business_escalation", "business_escalation"):
        ESCALATION_PENDING[chat_id] = True
        reply = answer_business_escalation(you, me)

    elif intent in ("menu_channels", "channels"):
        reply = answer_channels(you, me)

    elif intent == "smalltalk_thanks":
        reply = answer_smalltalk_thanks(you, me)

    elif intent == "product_by_code":
        code = extract_code(text)
        if code and code in PRODUCT_MAP:
            reply = format_product_by_code(code, you)
            matched_product_code = code
            matched_product_name = PRODUCT_MAP[code].get("name", "")
        else:
            reply = f"Em ch∆∞a t√¨m ƒë∆∞·ª£c m√£ s·∫£n ph·∫©m n√†y, {you} ki·ªÉm tra l·∫°i gi√∫p em nh√©. üôè"

    elif intent in ("combo_health", "health_products", "product_info", "product_correction"):
        reply, combo, product, parsed_for_log, ranking_for_log = orchestrate_health_answer(text, intent, you)

        if combo:
            matched_combo_id   = combo.get("id", "")
            matched_combo_name = combo.get("name", "")
        if product:
            matched_product_code = product.get("code", "")
            matched_product_name = product.get("name", "")

    else:
        reply = answer_fallback(you, me)

    # M∆∞·ª£t h√≥a b·∫±ng OpenAI (n·∫øu b·∫≠t)
    reply = polish_answer_with_ai(reply)

    # G·ª≠i l·∫°i cho TVV
    send_message(chat_id, reply, reply_markup=MAIN_KEYBOARD)

    # ---------------- LOG PH·ª§C V·ª§ AUTO-LEARNING ----------------
    parsed_symptoms = parsed_for_log.get("symptoms") if parsed_for_log else []
    parsed_goals    = parsed_for_log.get("goals") if parsed_for_log else []
    parsed_target   = parsed_for_log.get("target") if parsed_for_log else ""
    need_meal_plan  = bool(parsed_for_log.get("need_meal_plan")) if parsed_for_log else False
    health_tags     = ranking_for_log.get("tags") if ranking_for_log else []

    ranked_combos_list   = ranking_for_log.get("combos")   if ranking_for_log else []
    ranked_products_list = ranking_for_log.get("products") if ranking_for_log else []

    ranked_combos = [
        {
            "id": c.get("id"),
            "name": c.get("name"),
            "health_tags": c.get("health_tags", []),
        }
        for c in ranked_combos_list
    ]

    ranked_products = [
        {
            "code": p.get("code"),
            "name": p.get("name"),
            "health_tags": p.get("health_tags", []),
        }
        for p in ranked_products_list
    ]

    update_chat_context(
        chat_id,
        last_intent=intent,
        last_text=text,
        last_reply=reply,
        last_matched_combo_id=matched_combo_id,
        last_matched_combo_name=matched_combo_name,
        last_matched_product_code=matched_product_code,
        last_matched_product_name=matched_product_name,
    )

    log_payload = {
        "chat_id": chat_id,
        "user_name": user_name,
        "text": text,
        "bot_reply": reply,
        "intent": intent,

        "parsed_symptoms": parsed_symptoms,
        "parsed_goals": parsed_goals,
        "parsed_target": parsed_target,
        "need_meal_plan": need_meal_plan,
        "health_tags": health_tags,

        "matched_combo_id": matched_combo_id,
        "matched_combo_name": matched_combo_name,
        "matched_product_code": matched_product_code,
        "matched_product_name": matched_product_name,

        "ranked_combos": ranked_combos,
        "ranked_products": ranked_products,

        "final_combo_id": "",
        "final_product_code": "",
        "feedback": "",
    }
    log_to_sheet(log_payload)

    return jsonify(ok=True)

@app.route("/healthz", methods=["GET"])
def healthz():
    return "ok", 200

if __name__ == "__main__":
    app.run(host="0.0.0.0", port=8000, debug=True)
