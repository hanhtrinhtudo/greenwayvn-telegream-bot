import os
import json
import re
import unicodedata
import requests
from flask import Flask, request, jsonify
from dotenv import load_dotenv

# ============== OpenAI (ƒë·ªÉ hi·ªÉu intent & ‚Äúm∆∞·ª£t h√≥a‚Äù c√¢u tr·∫£ l·ªùi) ==============
try:
    from openai import OpenAI
except ImportError:
    OpenAI = None

# ============== ENV ==============
load_dotenv()

TELEGRAM_TOKEN = os.getenv("TELEGRAM_TOKEN", "")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY", "")

# Hotline, link ƒëi·ªÅu h∆∞·ªõng, tuy·∫øn tr√™n
HOTLINE_TUYEN_TREN = os.getenv("HOTLINE_TUYEN_TREN", "09xx.xxx.xxx")
LINK_KENH_TELEGRAM = os.getenv("LINK_KENH_TELEGRAM", "https://t.me/your_channel")
LINK_FANPAGE = os.getenv("LINK_FANPAGE", "https://facebook.com/your_fanpage")
LINK_WEBSITE = os.getenv("LINK_WEBSITE", "https://your-website.com")

# ID Telegram c·ªßa tuy·∫øn tr√™n (upline), d·∫°ng s·ªë (string trong .env)
UPLINE_CHAT_ID = os.getenv("UPLINE_CHAT_ID", "")

# Webhook Apps Script ƒë·ªÉ log v√†o Google Sheets
LOG_SHEET_WEBHOOK_URL = os.getenv("LOG_SHEET_WEBHOOK_URL", "")

# ============== KI·ªÇM TRA ENV ==============
if not TELEGRAM_TOKEN:
    raise ValueError("Thi·∫øu TELEGRAM_TOKEN trong .env")

# ============== OpenAI CLIENT ==============
client = None
if OpenAI and OPENAI_API_KEY:
    client = OpenAI(api_key=OPENAI_API_KEY)

# ============== FLASK APP ==============
app = Flask(__name__)

# ============== ƒê∆Ø·ªúNG D·∫™N JSON ==============
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
PRODUCTS_PATH = os.path.join(BASE_DIR, "products.json")
COMBOS_PATH = os.path.join(BASE_DIR, "combos.json")
FAQ_BUY_PATH = os.path.join(BASE_DIR, "faq_buy.json")
FAQ_PAYMENT_PATH = os.path.join(BASE_DIR, "faq_payment.json")
FAQ_BUSINESS_PATH = os.path.join(BASE_DIR, "faq_business.json")

# 2 file m·ªõi:
HEALTH_TAGS_MAP_PATH = os.path.join(BASE_DIR, "health_tags_map.json")
SYNONYMS_PATH = os.path.join(BASE_DIR, "synonyms.json")

# ============== T·∫¢I D·ªÆ LI·ªÜU JSON ==============
def safe_load_json(path, default=None):
    if default is None:
        default = {}
    try:
        if not os.path.exists(path):
            return default
        with open(path, "r", encoding="utf-8") as f:
            data = json.load(f)
        return data
    except Exception as e:
        print(f"[WARN] Kh√¥ng ƒë·ªçc ƒë∆∞·ª£c JSON {path}: {e}")
        return default

def extract_list(data, key=None):
    """
    combos.json: { "combos": [ ... ] }
    products.json: { "products": [ ... ] }
    """
    if isinstance(data, list):
        return data
    if isinstance(data, dict) and key and isinstance(data.get(key), list):
        return data[key]
    return []

# ƒë·ªçc d·ªØ li·ªáu th·∫≠t s·ª± d√πng
combos_raw = safe_load_json(COMBOS_PATH, default={"combos": []})
products_raw = safe_load_json(PRODUCTS_PATH, default={"products": []})
faq_buy_data = safe_load_json(FAQ_BUY_PATH, default=[])
faq_payment_data = safe_load_json(FAQ_PAYMENT_PATH, default=[])
faq_business_data = safe_load_json(FAQ_BUSINESS_PATH, default=[])

combos_list = extract_list(combos_raw, "combos")
products_list = extract_list(products_raw, "products")

# 2 file m·ªõi
health_tags_map_data = safe_load_json(HEALTH_TAGS_MAP_PATH, default={})
synonyms_data = safe_load_json(SYNONYMS_PATH, default={})

# ============== H√ÄM TI·ªÜN √çCH CHUNG ==============
def normalize_text(text: str) -> str:
    if not text:
        return ""
    text = text.lower().strip()
    text = unicodedata.normalize("NFD", text)
    text = "".join(ch for ch in text if unicodedata.category(ch) != "Mn")
    return text

def text_contains(text: str, keyword: str) -> bool:
    return normalize_text(keyword) in normalize_text(text)

def send_telegram_message(chat_id, text, reply_to_message_id=None, parse_mode="HTML"):
    url = f"https://api.telegram.org/bot{TELEGRAM_TOKEN}/sendMessage"
    payload = {
        "chat_id": chat_id,
        "text": text,
        "parse_mode": parse_mode,
        "disable_web_page_preview": False,
    }
    if reply_to_message_id:
        payload["reply_to_message_id"] = reply_to_message_id

    try:
        resp = requests.post(url, json=payload, timeout=15)
        if resp.status_code != 200:
            print("[ERROR] Telegram sendMessage:", resp.text)
    except Exception as e:
        print("[ERROR] G·ª≠i tin nh·∫Øn Telegram l·ªói:", e)

def log_to_sheet(payload: dict):
    if not LOG_SHEET_WEBHOOK_URL:
        return
    try:
        requests.post(LOG_SHEET_WEBHOOK_URL, json=payload, timeout=15)
    except Exception as e:
        print("[WARN] Log sheet l·ªói:", e)

# ============== ƒê·ªíNG B·ªò SYNONYMS & HEALTH TAGS ==============
def apply_synonyms(text: str) -> str:
    """
    Thay th·∫ø c√°c c·ª•m t·ª´ theo synonyms.json (bao t·ª≠ -> d·∫° d√†y, v.v.)
    Kh√¥ng ph√° v·ª° n·ªôi dung, ch·ªâ chu·∫©n h√≥a c√°ch g·ªçi.
    """
    if not text or not isinstance(synonyms_data, dict):
        return text
    result = text
    for k, v in synonyms_data.items():
        if not k or not v:
            continue
        try:
            pattern = re.compile(re.escape(k), flags=re.IGNORECASE)
            result = pattern.sub(v, result)
        except re.error:
            continue
    return result

def expand_health_issue(health_issue: str):
    """
    T·ª´ 1 c√¢u/ c·ª•m 'v·∫•n ƒë·ªÅ s·ª©c kho·∫ª' ‚Üí tr·∫£ v·ªÅ list:
    - [c√¢u g·ªëc, c√¢u sau khi √°p synonyms, c√°c health_tags trong health_tags_map n·∫øu match]
    """
    res = []
    if not health_issue:
        return res

    base = health_issue.strip()
    if base:
        res.append(base)

    # √Åp synonyms
    syn = apply_synonyms(base)
    if syn and syn not in res:
        res.append(syn)

    # D√πng health_tags_map ƒë·ªÉ m·ªü r·ªông
    try:
        h_norm = normalize_text(base)
        if isinstance(health_tags_map_data, dict):
            for key, tags in health_tags_map_data.items():
                try:
                    key_norm = normalize_text(str(key))
                except Exception:
                    continue
                if not key_norm:
                    continue
                if key_norm in h_norm or h_norm in key_norm:
                    if isinstance(tags, list):
                        for t in tags:
                            if t and t not in res:
                                res.append(t)
                    else:
                        if tags and tags not in res:
                            res.append(tags)
    except Exception as e:
        print("[WARN] expand_health_issue:", e)

    return res

# ============== T√åM KI·∫æM S·∫¢N PH·∫®M & COMBO ==============
def search_combo_by_health_issue(health_issue: str):
    """
    T√¨m combo theo v·∫•n ƒë·ªÅ s·ª©c kh·ªèe (d√πng health_tags & aliases & name),
    c√≥ s·ª≠ d·ª•ng health_tags_map + synonyms.
    """
    if not health_issue:
        return None

    issues = expand_health_issue(health_issue)
    if not issues:
        issues = [health_issue]

    best_score = 0
    best_combo = None

    for combo in combos_list:
        name = combo.get("name", "")
        aliases = combo.get("aliases", [])
        health_tags = combo.get("health_tags", [])

        fields = [name] + aliases + health_tags

        score = 0
        for issue in issues:
            i_norm = normalize_text(issue)
            for field in fields:
                if text_contains(field, i_norm) or text_contains(i_norm, field):
                    score += 1

        if score > best_score:
            best_score = score
            best_combo = combo

    return best_combo

def search_product_by_health_issue(health_issue: str):
    """
    T√¨m 1‚Äì3 s·∫£n ph·∫©m l·∫ª li√™n quan ƒë·∫øn v·∫•n ƒë·ªÅ s·ª©c kho·∫ª,
    c√≥ d√πng health_tags_map + synonyms.
    """
    if not health_issue:
        return []

    issues = expand_health_issue(health_issue)
    if not issues:
        issues = [health_issue]

    results = []
    for p in products_list:
        fields = []
        fields.append(p.get("name", ""))
        fields.extend(p.get("aliases", []))
        fields.extend(p.get("health_tags", []))
        main_tag = p.get("main_health_tag")
        if main_tag:
            fields.append(main_tag)

        match = False
        for issue in issues:
            i_norm = normalize_text(issue)
            for field in fields:
                if text_contains(field, i_norm) or text_contains(i_norm, field):
                    match = True
                    break
            if match:
                break

        if match:
            results.append(p)

    # Gi·ªõi h·∫°n 3 s·∫£n ph·∫©m cho ƒë·ª° lo√£ng
    return results[:3]

def search_product_by_name_or_code(query: str):
    """
    T√¨m s·∫£n ph·∫©m theo m√£ ho·∫∑c t√™n/alias.
    """
    if not query:
        return None

    # Chu·∫©n h√≥a b·∫±ng synonyms tr∆∞·ªõc khi normalize
    query = apply_synonyms(query)
    q_norm = normalize_text(query)
    best_score = 0
    best_product = None

    for p in products_list:
        code = p.get("code", "")
        name = p.get("name", "")
        aliases = p.get("aliases", [])

        fields = [code, name] + aliases
        score = 0
        for field in fields:
            if not field:
                continue
            if text_contains(field, q_norm) or text_contains(q_norm, field):
                score += 1
        if score > best_score:
            best_score = score
            best_product = p

    return best_product

# ============== OPENAI ‚Äì PH√ÇN T√çCH INTENT & NHU C·∫¶U ==============
def classify_intent_with_openai(user_text: str) -> dict:
    """
    D√πng OpenAI ƒë·ªÉ ph√¢n t√≠ch:
    - intent
    - health_issue
    - product_query
    - needs
    - ask_upline
    Tr·∫£ v·ªÅ dict chu·∫©n.
    """
    base_result = {
        "intent": "SMALL_TALK",
        "health_issue": None,
        "product_query": None,
        "needs": [],
        "ask_upline": False,
        "raw_reasoning": "",
    }

    if not client:
        # N·∫øu kh√¥ng c√≥ OpenAI th√¨ fallback keyword ƒë∆°n gi·∫£n
        t_raw = apply_synonyms(user_text or "")
        t = normalize_text(t_raw)
        if any(k in t for k in ["tieu duong", "ƒëai thao duong"]):
            base_result["intent"] = "HEALTH_COMBO"
            base_result["health_issue"] = "ti·ªÉu ƒë∆∞·ªùng"
        elif any(k in t for k in ["da day", "d·∫° d√†y", "bao tu", "bao t·ª≠", "trao nguoc"]):
            base_result["intent"] = "HEALTH_PRODUCT"
            base_result["health_issue"] = "ƒëau d·∫° d√†y / d·∫° d√†y"
        elif any(k in t for k in ["mua hang", "dat hang", "ƒë·∫∑t h√†ng", "mua nh∆∞ the nao", "mua nh∆∞ th·∫ø n√†o"]):
            base_result["intent"] = "HOW_TO_BUY"
        elif any(k in t for k in ["thanh toan", "thanh to√°n", "chuyen khoan", "chuy·ªÉn kho·∫£n"]):
            base_result["intent"] = "HOW_TO_PAY"
        elif any(k in t for k in ["fanpage", "kenh", "k√™nh", "website", "trang web"]):
            base_result["intent"] = "NAVIGATION"
        elif any(k in t for k in ["chinh sach", "hoa hong", "kinh doanh", "th∆∞·ªüng", "chi·∫øt kh·∫•u"]):
            base_result["intent"] = "BUSINESS_QUESTION"
        return base_result

    system_prompt = """
B·∫°n l√† tr·ª£ l√Ω AI n·ªôi b·ªô h·ªó tr·ª£ ƒë·ªôi ng≈© t∆∞ v·∫•n vi√™n (TVV) c·ªßa c√¥ng ty th·ª±c ph·∫©m chƒÉm s√≥c s·ª©c kh·ªèe.
Nhi·ªám v·ª•: ph√¢n t√≠ch c√¢u h·ªèi v√† tr·∫£ v·ªÅ JSON theo c·∫•u tr√∫c.

C√°c INTENT ch√≠nh:
- HEALTH_COMBO: TVV h·ªèi combo cho m·ªôt v·∫•n ƒë·ªÅ s·ª©c kh·ªèe (v√≠ d·ª•: ti·ªÉu ƒë∆∞·ªùng, huy·∫øt √°p, m·ª° m√°u...)
- HEALTH_PRODUCT: TVV h·ªèi s·∫£n ph·∫©m l·∫ª cho m·ªôt v·∫•n ƒë·ªÅ s·ª©c kh·ªèe.
- PRODUCT_DETAIL: TVV h·ªèi th√¥ng tin chi ti·∫øt v·ªÅ m·ªôt s·∫£n ph·∫©m c·ª• th·ªÉ (theo m√£ ho·∫∑c t√™n).
- HOW_TO_BUY: H·ªèi c√°ch mua h√†ng, ƒë·∫∑t h√†ng, quy tr√¨nh.
- HOW_TO_PAY: H·ªèi v·ªÅ c√°ch thanh to√°n, chuy·ªÉn kho·∫£n, COD.
- BUSINESS_QUESTION: H·ªèi v·ªÅ ch√≠nh s√°ch kinh doanh, hoa h·ªìng, chi·∫øt kh·∫•u, th∆∞·ªüng, quy ƒë·ªãnh n·ªôi b·ªô.
- NAVIGATION: H·ªèi xin link fanpage, k√™nh telegram, website, group ch√≠nh th·ª©c.
- SMALL_TALK: Ch√†o h·ªèi, c·∫£m ∆°n, c√¢u chuy·ªán chung chung.

Tr∆∞·ªùng "needs" l√† danh s√°ch c√°c nhu c·∫ßu c·ª• th·ªÉ trong c√πng 1 c√¢u:
- "combo": c·∫ßn t√™n combo
- "products": c·∫ßn danh s√°ch s·∫£n ph·∫©m trong combo
- "usage": c·∫ßn c√°ch d√πng/c√°ch u·ªëng
- "duration": c·∫ßn th·ªùi gian d√πng bao l√¢u ƒë·ªÉ c√≥ k·∫øt qu·∫£
- "product_links": c·∫ßn link s·∫£n ph·∫©m
- "benefits": c·∫ßn l·ª£i √≠ch/c√¥ng d·ª•ng
- "ingredients": c·∫ßn th√†nh ph·∫ßn s·∫£n ph·∫©m
- "how_to_buy": c·∫ßn h∆∞·ªõng d·∫´n mua h√†ng
- "how_to_pay": c·∫ßn h∆∞·ªõng d·∫´n thanh to√°n

Tr∆∞·ªùng "ask_upline":
- true: n·∫øu c√¢u h·ªèi thu·ªôc d·∫°ng BUSINESS_QUESTION kh√≥ ho·∫∑c nh·∫°y c·∫£m, n√™n chuy·ªÉn tuy·∫øn tr√™n.
- false: c√≤n l·∫°i.

Tr·∫£ v·ªÅ JSON v·ªõi c√°c field:
{
  "intent": "...",
  "health_issue": "... ho·∫∑c null",
  "product_query": "... ho·∫∑c null",
  "needs": [...],
  "ask_upline": false,
  "raw_reasoning": "gi·∫£i th√≠ch ng·∫Øn g·ªçn v√¨ sao ph√¢n lo·∫°i nh∆∞ v·∫≠y"
}

Lu√¥n tr·∫£ v·ªÅ ƒë√∫ng d·∫°ng JSON h·ª£p l·ªá.
"""

    # √Åp synonyms v√†o text tr∆∞·ªõc khi g·ª≠i l√™n OpenAI cho d·ªÖ hi·ªÉu
    processed_text = apply_synonyms(user_text or "")

    try:
        resp = client.chat.completions.create(
            model="gpt-4o-mini",
            response_format={"type": "json_object"},
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": processed_text},
            ],
        )
        content = resp.choices[0].message.content
        data = json.loads(content)
        for k, v in base_result.items():
            if k not in data:
                data[k] = v

        # Chu·∫©n h√≥a health_issue b·∫±ng synonyms lu√¥n
        if data.get("health_issue"):
            data["health_issue"] = apply_synonyms(data["health_issue"])

        return data
    except Exception as e:
        print("[ERROR] OpenAI classify_intent:", e)
        return base_result

# ============== BUILD C√ÇU TR·∫¢ L·ªúI ==============
def format_combo_reply(combo, needs, health_issue):
    if not combo:
        return (
            f"Hi·ªán t·∫°i em ch∆∞a t√¨m th·∫•y combo ph√π h·ª£p trong d·ªØ li·ªáu cho v·∫•n ƒë·ªÅ: <b>{health_issue}</b>.\n"
            "Anh/ch·ªã th·ª≠ m√¥ t·∫£ r√µ h∆°n t√¨nh tr·∫°ng ho·∫∑c li√™n h·ªá tuy·∫øn tr√™n ƒë·ªÉ ƒë∆∞·ª£c h·ªó tr·ª£ chi ti·∫øt h∆°n nh√©."
        )

    name = combo.get("name", "Combo ph√π h·ª£p")
    header_text = combo.get("header_text", "")
    duration_text = combo.get("duration_text", "")
    combo_url = combo.get("combo_url", "")
    products = combo.get("products", [])

    lines = []
    lines.append(f"<b>{name}</b>")
    if header_text:
        lines.append(header_text)

    # Danh s√°ch s·∫£n ph·∫©m trong combo
    if not needs or "products" in needs or "combo" in needs:
        if products:
            lines.append("")
            lines.append("<b>Th√†nh ph·∫ßn combo:</b>")
            for idx, p in enumerate(products, start=1):
                pname = p.get("name") or p.get("product_name") or p.get("product_code") or "S·∫£n ph·∫©m"
                role_text = p.get("role_text", "")
                dose_text = p.get("dose_text", "")
                product_url = p.get("product_url", "")
                line = f"{idx}. {pname}"
                if role_text:
                    line += f" ‚Äì {role_text}"
                if dose_text:
                    line += f"\n   üëâ C√°ch d√πng: {dose_text}"
                if product_url and ("product_links" in needs or not needs):
                    line += f"\n   üîó Link: {product_url}"
                lines.append(line)

    # Th·ªùi gian s·ª≠ d·ª•ng
    if (not needs) or ("duration" in needs):
        if duration_text:
            lines.append("")
            lines.append(f"‚è± <b>Th·ªùi gian khuy·∫øn ngh·ªã:</b> {duration_text}")

    lines.append("")
    if combo_url and ("product_links" in needs or not needs):
        lines.append(f"üõí Link combo (n·∫øu ƒë·∫∑t online): {combo_url}")
        lines.append("")

    lines.append(
        "L∆∞u √Ω: ƒê√¢y l√† s·∫£n ph·∫©m h·ªó tr·ª£, kh√¥ng thay th·∫ø thu·ªëc ƒëi·ªÅu tr·ªã. "
        "Anh/ch·ªã TVV n√™n h·ªèi k·ªπ t√¨nh tr·∫°ng v√† thu·ªëc ƒëang d√πng tr∆∞·ªõc khi t∆∞ v·∫•n cho kh√°ch."
    )

    return "\n".join(lines)

def format_product_reply(product, needs, health_issue=None):
    if not product:
        if health_issue:
            return (
                f"Em ch∆∞a t√¨m th·∫•y s·∫£n ph·∫©m ph√π h·ª£p trong d·ªØ li·ªáu cho v·∫•n ƒë·ªÅ: <b>{health_issue}</b>.\n"
                "Anh/ch·ªã th·ª≠ m√¥ t·∫£ r√µ h∆°n tri·ªáu ch·ª©ng ho·∫∑c xin combo t·ªïng th·ªÉ ƒë·ªÉ t∆∞ v·∫•n d·ªÖ h∆°n nh√©."
            )
        return "Em ch∆∞a t√¨m th·∫•y s·∫£n ph·∫©m ph√π h·ª£p trong d·ªØ li·ªáu. Anh/ch·ªã ki·ªÉm tra l·∫°i t√™n ho·∫∑c m√£ s·∫£n ph·∫©m gi√∫p em nh√©."

    name = product.get("name", "S·∫£n ph·∫©m")
    code = product.get("code", "")
    ingredients = product.get("ingredients_text", "")
    benefits = product.get("benefits_text", "")
    usage = product.get("usage_text", "")
    price_text = product.get("price_text", "")
    duration_text = product.get("duration_text", "")  # c√≥ th·ªÉ ch∆∞a c√≥ trong file, kh√¥ng sao
    product_url = product.get("product_url", "")
    warnings = product.get("notes_for_tvv", "")

    lines = []
    title = f"<b>{name}</b>"
    if code:
        title += f" (M√£: {code})"
    lines.append(title)

    if price_text:
        lines.append(f"üí∞ Gi√° tham kh·∫£o: {price_text}")

    # Th√†nh ph·∫ßn
    if (not needs) or ("ingredients" in needs):
        if ingredients:
            lines.append("")
            lines.append(f"<b>Th√†nh ph·∫ßn ch√≠nh:</b> {ingredients}")

    # L·ª£i √≠ch
    if (not needs) or ("benefits" in needs):
        if benefits:
            lines.append("")
            lines.append("<b>L·ª£i √≠ch n·ªïi b·∫≠t:</b>")
            lines.append(benefits)

    # C√°ch d√πng
    if (not needs) or ("usage" in needs):
        if usage:
            lines.append("")
            lines.append(f"<b>C√°ch d√πng khuy·∫øn ngh·ªã:</b> {usage}")

    # Th·ªùi gian s·ª≠ d·ª•ng (n·∫øu c√≥)
    if (not needs) or ("duration" in needs):
        if duration_text:
            lines.append("")
            lines.append(f"<b>Th·ªùi gian s·ª≠ d·ª•ng n√™n duy tr√¨:</b> {duration_text}")

    # Link
    if (not needs) or ("product_links" in needs):
        if product_url:
            lines.append("")
            lines.append(f"üîó <b>Link s·∫£n ph·∫©m:</b> {product_url}")

    # C·∫£nh b√°o / l∆∞u √Ω cho TVV
    if warnings:
        lines.append("")
        lines.append(f"‚ö† <b>L∆∞u √Ω cho TVV:</b> {warnings}")

    lines.append("")
    lines.append(
        "Anh/ch·ªã TVV l∆∞u √Ω t∆∞ v·∫•n r√µ ƒë√¢y l√† s·∫£n ph·∫©m h·ªó tr·ª£, kh√¥ng thay th·∫ø thu·ªëc ƒëi·ªÅu tr·ªã, "
        "khuy·∫øn kh√≠ch kh√°ch tham kh·∫£o √Ω ki·∫øn b√°c sƒ© n·∫øu ƒëang d√πng thu·ªëc ho·∫∑c c√≥ b·ªánh n·ªÅn n·∫∑ng."
    )

    return "\n".join(lines)

def format_faq_reply(faq_list, key_field="title"):
    """
    faq_list: c√≥ th·ªÉ l√† list string ho·∫∑c list object {title, content}
    """
    if not faq_list:
        return "Hi·ªán t·∫°i em ch∆∞a c√≥ d·ªØ li·ªáu h∆∞·ªõng d·∫´n chi ti·∫øt trong h·ªá th·ªëng. Anh/ch·ªã gi√∫p em li√™n h·ªá tuy·∫øn tr√™n ƒë·ªÉ ƒë∆∞·ª£c h·ªó tr·ª£ nh√©."

    # N·∫øu l√† list string
    if all(isinstance(x, str) for x in faq_list):
        return "\n".join(faq_list)

    # N·∫øu l√† list object
    lines = []
    for i, item in enumerate(faq_list, start=1):
        if isinstance(item, str):
            lines.append(item)
        elif isinstance(item, dict):
            title = item.get(key_field, f"B∆∞·ªõc {i}")
            content = item.get("content", "")
            line = f"{i}. <b>{title}</b>"
            if content:
                line += f"\n   {content}"
            lines.append(line)
    return "\n\n".join(lines)

def format_navigation_reply():
    lines = []
    lines.append("<b>C√°c k√™nh ch√≠nh th·ª©c c·ªßa c√¥ng ty:</b>")
    if LINK_KENH_TELEGRAM:
        lines.append(f"üì¢ K√™nh Telegram: {LINK_KENH_TELEGRAM}")
    if LINK_FANPAGE:
        lines.append(f"üëç Fanpage Facebook: {LINK_FANPAGE}")
    if LINK_WEBSITE:
        lines.append(f"üåê Website: {LINK_WEBSITE}")
    lines.append("")
    lines.append("Anh/ch·ªã TVV nh·ªõ ∆∞u ti√™n d·∫´n kh√°ch v√†o c√°c k√™nh ch√≠nh th·ª©c n√†y ƒë·ªÉ theo d√µi ch∆∞∆°ng tr√¨nh v√† th√¥ng tin m·ªõi nh·∫•t nh√©.")
    return "\n".join(lines)

# ============== X·ª¨ L√ù C√ÇU H·ªéI KINH DOANH & CHUY·ªÇN TUY·∫æN TR√äN ==============
def match_business_faq(user_text: str):
    """
    T√¨m c√¢u tr·∫£ l·ªùi trong faq_business_data n·∫øu c√≥.
    C·∫•u tr√∫c g·ª£i √Ω: [{"q_keywords":["hoa h·ªìng","chi·∫øt kh·∫•u"], "answer":"..."}]
    """
    if not faq_business_data:
        return None

    t_raw = apply_synonyms(user_text or "")
    t = normalize_text(t_raw)

    for item in faq_business_data:
        try:
            keywords = item.get("q_keywords", [])
            if not keywords:
                continue
            if all(normalize_text(k) in t for k in keywords):
                return item.get("answer")
        except Exception:
            continue
    return None

def escalate_to_upline(chat_id, username, text):
    """
    G·ª≠i c√¢u h·ªèi l√™n tuy·∫øn tr√™n, log l·∫°i.
    """
    if not UPLINE_CHAT_ID:
        return "Hi·ªán t·∫°i em ch∆∞a c·∫•u h√¨nh tuy·∫øn tr√™n trong h·ªá th·ªëng. Anh/ch·ªã vui l√≤ng li√™n h·ªá tr·ª±c ti·∫øp l√£nh ƒë·∫°o ƒë·ªÉ ƒë∆∞·ª£c h·ªó tr·ª£."

    msg = (
        f"üì® <b>Y√äU C·∫¶U H·ªñ TR·ª¢ TUY·∫æN TR√äN</b>\n\n"
        f"üë§ TVV: @{username if username else 'Kh√¥ng r√µ'}\n"
        f"üí¨ Chat ID: <code>{chat_id}</code>\n\n"
        f"‚ùì N·ªôi dung:\n{text}"
    )
    send_telegram_message(UPLINE_CHAT_ID, msg, parse_mode="HTML")

    return (
        "V·∫•n ƒë·ªÅ n√†y thu·ªôc nh√≥m ch√≠nh s√°ch/kinh doanh ho·∫∑c t√¨nh hu·ªëng kh√≥, "
        "em ƒë√£ chuy·ªÉn n·ªôi dung l√™n tuy·∫øn tr√™n ƒë·ªÉ h·ªó tr·ª£ anh/ch·ªã. "
        "Khi c√≥ ph·∫£n h·ªìi, em s·∫Ω g·ª≠i l·∫°i ngay ·∫°. üìû"
    )

def handle_upline_reply(upline_text: str):
    """
    X·ª≠ l√Ω l·ªánh /reply t·ª´ tuy·∫øn tr√™n:
    Format: /reply <chat_id> <n·ªôi dung>
    """
    parts = upline_text.split(maxsplit=2)
    if len(parts) < 3:
        return None, "Sai c√∫ ph√°p. D√πng: /reply <chat_id> <n·ªôi dung>"

    _, chat_id_str, content = parts
    if not chat_id_str.isdigit():
        return None, "Chat ID ph·∫£i l√† s·ªë. V√≠ d·ª•: /reply 123456789 N·ªôi dung tr·∫£ l·ªùi"

    return int(chat_id_str), content

# ============== X·ª¨ L√ù LOGIC CH√çNH ==============
def build_ai_style_reply(user_text: str, core_answer: str) -> str:
    """
    Nh·ªù OpenAI ch·ªânh c√¢u tr·∫£ l·ªùi cho m·ªÅm m·∫°i h∆°n, gi·ªØ nguy√™n th√¥ng tin ch√≠nh.
    N·∫øu kh√¥ng c√≥ OpenAI, tr·∫£ v·ªÅ core_answer lu√¥n.
    """
    if not client:
        return core_answer

    prompt = f"""
B·∫°n l√† tr·ª£ l√Ω AI n·ªôi b·ªô, x∆∞ng h√¥ "em" v·ªõi TVV, TVV l√† "anh/ch·ªã".
H√£y gi·ªØ nguy√™n c√°c th√¥ng tin quan tr·ªçng (s·ªë l∆∞·ª£ng, li·ªÅu d√πng, th·ªùi gian, t√™n s·∫£n ph·∫©m),
ch·ªâ vi·∫øt l·∫°i cho m·ªÅm m·∫°i, th√¢n thi·ªán, r√µ r√†ng, d·ªÖ ƒë·ªçc.

C√¢u h·ªèi c·ªßa TVV:
\"\"\"{user_text}\"\"\"

D∆∞·ªõi ƒë√¢y l√† n·ªôi dung c·ªët l√µi c·∫ßn truy·ªÅn ƒë·∫°t, b·∫°n ƒë∆∞·ª£c ph√©p ch·ªânh c√¢u ch·ªØ nh∆∞ng kh√¥ng ƒë∆∞·ª£c b·ªãa th√¥ng tin m·ªõi:
\"\"\"{core_answer}\"\"\"
"""
    try:
        resp = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": "B·∫°n l√† tr·ª£ l√Ω b√°n h√†ng n·ªôi b·ªô cho TVV, tr·∫£ l·ªùi b·∫±ng ti·∫øng Vi·ªát, th√¢n thi·ªán, r√µ r√†ng."},
                {"role": "user", "content": prompt},
            ],
        )
        return resp.choices[0].message.content
    except Exception as e:
        print("[ERROR] OpenAI build_ai_style_reply:", e)
        return core_answer

def handle_user_message(chat_id, text, username=None, msg_id=None):
    """
    H√†m trung t√¢m x·ª≠ l√Ω tin nh·∫Øn t·ª´ TVV.
    Gi·ªØ nguy√™n logic c≈©, ch·ªâ th√™m b∆∞·ªõc √°p synonyms + health_tags_map.
    """
    intent_info = classify_intent_with_openai(text)
    intent = intent_info.get("intent", "SMALL_TALK")
    health_issue = intent_info.get("health_issue")
    product_query = intent_info.get("product_query")
    needs = intent_info.get("needs") or []
    ask_upline = bool(intent_info.get("ask_upline", False))

    # Log s∆° b·ªô
    log_payload = {
        "source": "telegram",
        "chat_id": str(chat_id),
        "username": username or "",
        "user_text": text,
        "intent": intent,
        "health_issue": health_issue or "",
        "product_query": product_query or "",
    }

    reply_text_core = ""

    # ====== PH√ÇN NH√ÅNH THEO INTENT ======
    if intent in ["HEALTH_COMBO"]:
        combo = search_combo_by_health_issue(health_issue or text)
        reply_text_core = format_combo_reply(combo, needs, health_issue or text)

    elif intent in ["HEALTH_PRODUCT"]:
        # N·∫øu truy v·∫•n s·∫£n ph·∫©m c·ª• th·ªÉ
        if product_query:
            product = search_product_by_name_or_code(product_query)
            reply_text_core = format_product_reply(product, needs, health_issue=None)
        else:
            products = search_product_by_health_issue(health_issue or text)
            if not products:
                reply_text_core = format_product_reply(None, needs, health_issue or text)
            elif len(products) == 1:
                reply_text_core = format_product_reply(products[0], needs, health_issue or text)
            else:
                # Nhi·ªÅu s·∫£n ph·∫©m, li·ªát k√™ g·ª£i √Ω
                lines = [f"<b>M·ªôt s·ªë s·∫£n ph·∫©m ph√π h·ª£p v·ªõi v·∫•n ƒë·ªÅ {health_issue or text}:</b>"]
                for p in products:
                    name = p.get("name", "S·∫£n ph·∫©m")
                    code = p.get("code", "")
                    url = p.get("product_url", "")
                    line = f"‚Ä¢ {name}"
                    if code:
                        line += f" (M√£: {code})"
                    if url:
                        line += f"\n   üîó {url}"
                    lines.append(line)
                lines.append("")
                lines.append("N·∫øu anh/ch·ªã mu·ªën xem chi ti·∫øt s·∫£n ph·∫©m n√†o, h√£y h·ªèi theo t√™n ho·∫∑c m√£ s·∫£n ph·∫©m c·ª• th·ªÉ nh√©.")
                reply_text_core = "\n".join(lines)

    elif intent in ["PRODUCT_DETAIL"]:
        product = search_product_by_name_or_code(product_query or text)
        reply_text_core = format_product_reply(product, needs, health_issue=None)

    elif intent == "HOW_TO_BUY":
        reply_text_core = format_faq_reply(faq_buy_data)
    elif intent == "HOW_TO_PAY":
        reply_text_core = format_faq_reply(faq_payment_data)
    elif intent == "NAVIGATION":
        reply_text_core = format_navigation_reply()
    elif intent == "BUSINESS_QUESTION":
        # Th·ª≠ tr·∫£ l·ªùi t·ª´ FAQ n·ªôi b·ªô
        faq_answer = match_business_faq(text)
        if faq_answer:
            reply_text_core = faq_answer
        else:
            # N·∫øu ƒë∆∞·ª£c g·ª£i √Ω ask_upline ho·∫∑c kh√¥ng c√≥ d·ªØ li·ªáu
            ask_upline = True
            reply_text_core = escalate_to_upline(chat_id, username, text)
    else:
        # SMALL_TALK ho·∫∑c kh√¥ng r√µ
        reply_text_core = (
            "Em l√† tr·ª£ l√Ω AI n·ªôi b·ªô h·ªó tr·ª£ anh/ch·ªã TVV trong vi·ªác t∆∞ v·∫•n s·∫£n ph·∫©m, combo v√† c√°ch chƒÉm s√≥c s·ª©c kho·∫ª.\n\n"
            "Anh/ch·ªã c√≥ th·ªÉ h·ªèi em v·ªÅ:\n"
            "‚Ä¢ Combo cho m·ªôt v·∫•n ƒë·ªÅ s·ª©c kh·ªèe (v√≠ d·ª•: ti·ªÉu ƒë∆∞·ªùng, d·∫° d√†y, x∆∞∆°ng kh·ªõp...)\n"
            "‚Ä¢ Th√¥ng tin chi ti·∫øt m·ªôt s·∫£n ph·∫©m (th√†nh ph·∫ßn, l·ª£i √≠ch, c√°ch d√πng...)\n"
            "‚Ä¢ C√°ch mua h√†ng, thanh to√°n, k√™nh ch√≠nh th·ª©c c·ªßa c√¥ng ty\n"
            "‚Ä¢ Nh·ªØng th·∫Øc m·∫Øc v·ªÅ kinh doanh, ch√≠nh s√°ch (em s·∫Ω h·ªó tr·ª£ chuy·ªÉn tuy·∫øn tr√™n n·∫øu c·∫ßn) üòä"
        )

    # ====== LOG TH√äM TH√îNG TIN ======
    log_payload["ask_upline"] = "yes" if ask_upline else "no"
    log_payload["final_answer_preview"] = reply_text_core[:500]
    log_to_sheet(log_payload)

    # ====== NH·ªú AI ‚ÄúM·ªÄM H√ìA‚Äù C√ÇU TR·∫¢ L·ªúI ======
    final_reply = build_ai_style_reply(text, reply_text_core)

    send_telegram_message(chat_id, final_reply, reply_to_message_id=msg_id)

# ============== ROUTES FLASK ==============
@app.route("/", methods=["GET"])
def index():
    return jsonify({"status": "ok", "message": "Welllab AI Assistant is running."})

@app.route("/webhook", methods=["POST"])
def telegram_webhook():
    update = request.get_json(force=True, silent=True) or {}

    message = update.get("message") or update.get("edited_message")
    if not message:
        return jsonify({"ok": True})

    chat = message.get("chat", {})
    chat_id = chat.get("id")
    from_user = message.get("from", {})
    username = from_user.get("username") or from_user.get("first_name")
    text = message.get("text", "") or ""

    # N·∫øu l√† tin t·ª´ tuy·∫øn tr√™n (upline)
    if UPLINE_CHAT_ID and str(chat_id) == str(UPLINE_CHAT_ID):
        if text.startswith("/reply"):
            target_chat_id, content = handle_upline_reply(text)
            if not target_chat_id:
                send_telegram_message(chat_id, content)
            else:
                # G·ª≠i n·ªôi dung cho TVV
                send_telegram_message(target_chat_id, f"üì£ Ph·∫£n h·ªìi t·ª´ tuy·∫øn tr√™n:\n\n{content}")
                send_telegram_message(chat_id, "ƒê√£ g·ª≠i tr·∫£ l·ªùi cho TVV.")
        else:
            send_telegram_message(
                chat_id,
                "ƒê√¢y l√† k√™nh tuy·∫øn tr√™n. ƒê·ªÉ tr·∫£ l·ªùi TVV, d√πng l·ªánh:\n/reply <chat_id> <n·ªôi dung>",
            )
        return jsonify({"ok": True})

    # X·ª≠ l√Ω l·ªánh /start
    if text.startswith("/start"):
        welcome = (
            "Ch√†o anh/ch·ªã, em l√† <b>Tr·ª£ l√Ω AI Welllab</b> h·ªó tr·ª£ ƒë·ªôi ng≈© TVV üíö\n\n"
            "Anh/ch·ªã c√≥ th·ªÉ h·ªèi em v·ªÅ:\n"
            "‚Ä¢ Combo cho c√°c v·∫•n ƒë·ªÅ s·ª©c kh·ªèe (ti·ªÉu ƒë∆∞·ªùng, d·∫° d√†y, m·ª° m√°u, x∆∞∆°ng kh·ªõp...)\n"
            "‚Ä¢ Th√¥ng tin chi ti·∫øt s·∫£n ph·∫©m (th√†nh ph·∫ßn, l·ª£i √≠ch, c√°ch d√πng...)\n"
            "‚Ä¢ C√°ch mua h√†ng, thanh to√°n, k√™nh ch√≠nh th·ª©c c·ªßa c√¥ng ty\n"
            "‚Ä¢ C√¢u h·ªèi kinh doanh, ch√≠nh s√°ch (em s·∫Ω h·ªó tr·ª£ chuy·ªÉn tuy·∫øn tr√™n n·∫øu c·∫ßn)\n\n"
            "Anh/ch·ªã c·ª© nh·∫Øn t·ª± nhi√™n nh∆∞ ƒëang h·ªèi m·ªôt leader nh√© ü•∞"
        )
        send_telegram_message(chat_id, welcome, reply_to_message_id=message.get("message_id"))
        return jsonify({"ok": True})

    # C√°c tin nh·∫Øn c√≤n l·∫°i
    handle_user_message(chat_id, text, username=username, msg_id=message.get("message_id"))

    return jsonify({"ok": True})

# ============== MAIN ==============
if __name__ == "__main__":
    port = int(os.getenv("PORT", "8000"))
    app.run(host="0.0.0.0", port=port)
